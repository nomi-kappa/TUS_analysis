---
title: "GNG_TUS_Study_1_320trials_ANALYSIS"
author: "nomi"
date: "2023-10-31"
output: html_document
---

#READ FILE
```{r setup, include=FALSE}
library(readr)
tus <- read_csv("GNG_TUS_S1.csv")
View(tus)
```

#Load libraries
```{r}
library(lmerTest)
#library(lMest)
library(dplyr)
library(BayesFactor)
library(leaps)
library(tidyverse)
library(BANOVA)
library (rstan)
library(afex)
library(rstanarm)
library(stringr)
library(report)
library(jtools) #for explanation of lmer
library(emmeans)#2 prefictor, one should be continuous (the "var")
library(effects)
library(lme4)
library(bbmle)
library(MASS)
library(MuMIn)
library(AICcmodavg)#https://www.scribbr.com/statistics/akaike-information-criterion/#:~:text=Once%20you've%20created%20several,be%20the%20better%2Dfit%20model.
#help to interpret results from AICmodavg
library(lspline)
```

#Analysis

  ##Accuracy

   
      #comparing glmer models - Logistic regression
             ####???Should check for multicollinearity by calculating a Variance Inflation Factor (VIF) for each independent variable maybe?

```{r}
#as.factor
tus$req_action<-as.factor(tus$req_action); class (tus$req_action)

# refactor reference level
tus <- within(tus, req_action <- relevel(req_action, ref = "noGo"))



#Equivalent of stepAIC for glmer - comparing models - do not like it

      #WAY_1
# List of fixed effects
fixed_effects <- c("OutValence", "req_action", "condition", "trial_number")

# Generate all possible combinations of two-way interactions
interaction_terms_2way <- combn(fixed_effects, 2, simplify = FALSE) %>%
  lapply(function(x) paste(x, collapse = "*"))

# Generate all possible combinations of three-way interactions
interaction_terms_3way <- combn(fixed_effects, 3, simplify = FALSE) %>%
  lapply(function(x) paste(x, collapse = "*"))

# Combine two-way and three-way interaction terms
interaction_terms <- c(interaction_terms_2way, interaction_terms_3way)

# Check if there are valid combinations
if (length(interaction_terms) == 0) {
  cat("No valid combinations of interactions found.")
} else {
  # List to store models and AIC values
  model_list <- list()
  
  # Loop through each combination of interactions and fit models
  for (i in seq_along(interaction_terms)) {
    # Create formula string with interactions and random intercept
    formula_str <- as.formula(paste("correct ~", interaction_terms[[i]], "+ (1|ID)"))
    
    # Fit the model
    tryCatch({
      temp_model <- glmer(formula_str, data = tus, family = "binomial",
                          glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun=100000)))
      
      # Calculate AIC and store the model
      temp_AIC <- AIC(temp_model)
      model_list[[interaction_terms[[i]]]] <- list(model = temp_model, AIC = temp_AIC)
    }, error = function(e) {
      cat("Error occurred with this formula:", deparse(formula_str), "\n")
    })
  }
  
  # Order models by AIC value
  ordered_models <- model_list[order(sapply(model_list, function(x) x$AIC))]
  
  # Print the ordered models
  print(ordered_models)
}


        #WAY_2


# Step 1: Fit a series of GLM models (good models without the overfitted: 4 and 9 and 9.b is decent 8, 7, 6, 3, 1 (5 nearly unidentifiable))

        #all main effects are significant 
model1 <- glmer(correct ~ OutValence + req_action + condition +(1|ID) , 
                 data  = tus, family="binomial", glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE
        #all main effects are significant
model2 <- glmer(correct ~ OutValence + req_action + condition + trial_number +(1|ID) , 
                 data  = tus, family="binomial", glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE
#all main effects and interaction is significant. val*req_action = Cue
model3 <- glmer(correct ~ OutValence * req_action + condition + trial_number +(1|ID) , 
                 data  = tus, family="binomial", glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE

model4 <- glmer(correct ~ OutValence * req_action * condition +(1|ID) , 
                 data  = tus, family="binomial", glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE
#this is probably the one!

model4.b <- glmer(correct ~ OutValence * req_action * condition + trial_number +(1|ID) , 
                 data  = tus, family="binomial", glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE

model0 <- glmer(correct ~condition + req_action + condition*req_action + OutValence + condition*OutValence + req_action*OutValence +(1|ID) , 
                 data  = tus, family="binomial", glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE
summary(model0)#ignore most probably
model5 <- glmer(correct ~ OutValence * req_action * condition * trial_number +(1|ID) , 
                 data  = tus, family="binomial", glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE

model6 <- glmer(correct ~ Cue + condition + trial_number +(1|ID) , 
                 data  = tus, family="binomial", glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE

model7 <- glmer(correct ~ Cue + condition + OutValence + trial_number +(1|ID) , 
                 data  = tus, family="binomial", glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE

model8 <- glmer(correct ~ Cue * condition + trial_number +(1|ID) , 
                 data  = tus, family="binomial", glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE

model9 <- glmer(correct ~ Cue * condition * trial_number +(1|ID) , 
                 data  = tus, family="binomial", glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE
summary(model9)#not 9


model9.b <- glmer(correct ~ Cue * condition + trial_number +(1|ID) , 
                 data  = tus, family="binomial", glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE
summary(model9.b)

model10 <- glmer(correct ~ Cue * condition * OutValence* req_action* trial_number +(1|ID) , 
                 data  = tus, family="binomial", glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE
summary(model10)
model11 <- glmer(correct ~  OutValence * req_action *condition * trial_number + RT + (1|ID) ,
                   data = tus, family="binomial", glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE
summary(model11)#not11
model12 <-glmer(correct ~ OutValence + req_action + condition + RT +trial_number +(1|ID) , 
                 data  = tus, family="binomial", glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE

model13 <-glmer(correct ~ OutValence + req_action + condition + RT +(1|ID) , 
                 data  = tus, family="binomial", glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE

model14 <- glmer(correct ~ OutValence + req_action + condition + trial_number + (OutValence * req_action * condition * trial_number) + (1|ID) ,        
                 data  = tus, family="binomial", glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))); summary (model14) #REML = FALSE
#overfit i think 14, but also OutValenceWin:conditionc.ai:trial_number                  -0.0050235  0.0013815  -3.636 0.000277 ***
model15 <- glmer(correct ~ req_action + OutValence + trial_number + condition +(1|ID) + ( req_action + OutValence + trial_number + condition|ID), 
                 data  = tus, family="binomial",  glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE
#no 15
model16 <- glmer(correct ~ req_action * OutValence + trial_number + condition +(1|ID) + ( req_action * OutValence + trial_number + condition|ID), 
                 data  = tus, family="binomial",  glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE
 #takes ages and crashes
model17 <- glmer(correct ~ req_action * OutValence * trial_number * condition +(1|ID) + ( req_action * OutValence * trial_number * condition|ID), 
                 data  = tus, family="binomial",  glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE

model18 <- glmer(correct ~ req_action + OutValence + trial_number + condition +RT +(1|ID) + ( req_action * OutValence * trial_number * condition +RT|ID), 
                 data  = tus, family="binomial",  glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE

model19 <- glmer(correct ~ req_action * OutValence * trial_number * condition *RT +(1|ID) + ( req_action * OutValence * trial_number * condition *RT|ID), 
                 data  = tus, family="binomial",  glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5))) #REML = FALSE




#model 20 not working atm
# Identify non-numeric columns
non_numeric_cols <- c("req_action", "OutValence", "trial_number", "condition", "RT")

# Convert non-numeric values to NA
tus[, non_numeric_cols] <- lapply(tus[, non_numeric_cols], function(x) {
  as.numeric(as.character(x))
})

# Replace missing values with column means
tus[, non_numeric_cols] <- lapply(tus[, non_numeric_cols], function(x) {
  ifelse(is.na(x), mean(x, na.rm = TRUE), x)
})

# Scale numeric columns
scaled_tus <- tus
scaled_tus[, non_numeric_cols] <- scale(tus[, non_numeric_cols])

# Check the class of ID column
class(scaled_tus$ID)

# Convert ID to factor if it's not already a factor
if (!is.factor(scaled_tus$ID)) {
  scaled_tus$ID <- as.factor(scaled_tus$ID)
}

model20 <- glmer(correct ~ req_action * OutValence * trial_number * condition * RT + (1|ID),
                 data = scaled_tus, family = binomial,
                 glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))




# Step 2: Create a data frame with model names and AIC values
models_data <- data.frame(
  Model = c("model1", "model2", "model3", "model4", "model5", "model6", "model7", "model8", "model9", "model10", "model11", "model12",  "model13", "model14"),#, "model15", "model16", "model17", "model18", "model19"),
  AIC = c(AIC(model1), AIC(model2), AIC(model3), AIC(model4), AIC(model5), AIC(model6), AIC(model7), AIC(model8), AIC(model9), AIC(model10), AIC(model11), AIC(model12), AIC(model13), AIC(model14)))
  
  #, #AIC(model15), AIC(model16), AIC(model17), AIC(model18), AIC(model19)))
                          

models_data$AIC <- as.numeric(models_data$AIC)
# Step 3: Order the data frame based on AIC values
models_data <- models_data[order(models_data$AIC), ]


# Step 4:Output the ordered models and AIC values
cat("Ordered AIC values:\n")
print(models_data)


      #OR preferable
# Step 2: Compare models using aictab
# Create the AIC table
aictab_result <- aictab(cand.set = list(model1, model2, model3, model4, model5, model11, model12, model13))#, model14, model15, model16, model17, model18, model19),
  modnames = c("model1", "model2", "model3", "model4", "model5",  "model11", "model12", "model13")#, "model14", "model15", "model16", "model17", "model18", "model19"))

# Step 3: Reorder the AIC table by AICc values
aictab_result <- aictab_result[order(aictab_result$AICc), ]

# Step: 4Print the reordered AIC table
print(aictab_result)

```

#Summary models above
```{r}
# Assuming you have a list of 10 models named model1, model2, ..., model10
model_list <- list(model1, model2, model3, model4, model5, model11, model12, model13)

# Use lapply to get summaries for all models
model_summaries <- lapply(model_list, summary)

# Now you can access each summary using model_summaries[[1]], model_summaries[[2]], and so on
model_summaries[[1]]

#
summ(model1)
```

```{r}
# do not hot to combine the allmeans or alleffects to check the beta basic level main effects.
```

#Plotting the effects? Help - NOT WORKING
```{r}
#Not sure how to interpret the model (whichever I pick) or how to plot:
acc <- allEffects(model_acc, xlevels=list(req_action=seq(0, 24, 6)),
                   fixed.predictors=list(given.values=c(OutValenceWin =0.5)));acc

as.data.frame(acc[[]])

# the following are equivalent:
eff.ne <- effect("OutValence*req_action", model_acc)
Eff.ne <- Effect(c("OutValence", "req_action"), model_acc)
all.equal(eff.ne$fit, Eff.ne$fit)

# Assuming you have extracted the estimated effects into a data frame
# For example, using as.data.frame(eff.cowles[[2]])-->
# Create a ggplot object - not working yet
acc<-as.data.frame(acc)
ggplot(data =acc, aes(x = req_action, y = fit)) +
  geom_point() +  # Add points to the plot
  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.2) +  # Add error bars
  labs(x = "req_action", y = "Effect") +  # Label the axes
  ggtitle("Estimated Effects of req_action")  # Add a title

#or  #not working either - i do not know
plot(acc, 'OutValence', axes=list(grid=TRUE,
y=list(lab="condition"),
x=list(rotate=90)),
lines=list(lty=0))
```


#run anovaBF (not the correct analysis as the DV is categorical - just trying)
```{r}
#drop NAs
# Assuming 'df' is your data frame and 'column_name' is the name of the column you want to delete
df <- subset(tus, select = -log_rt)

df <- na.omit(df); View(df)
df$ID <- as.factor(df$ID)
df$correct <- as.integer(df$correct)
df$req_action <- as.factor(df$req_action)
df$condition <- as.factor(df$condition)
df$trial_number <- as.factor(df$trial_number)
df$OutValence <- as.factor(df$OutValence)
df$Cue <- as.factor(df$Cue)
df$block <- as.factor(df$block)


#anovaBF IV = req_action
 accu <-anovaBF(correct ~ OutValence*req_action*condition*trial_number  + ID, data = df, whichRandom = "ID",
   progress=FALSE); accu
accu[17]/accu[12]
accu/max(accu)#best models as denominator to so the closest ones

#anovaBF IV = Cue - interaction between the Cue and the condition
accu_cue <-anovaBF(correct ~ Cue*condition  + ID, data = df, whichRandom = "ID",
   progress=FALSE)
accu_cue[4]/accu_cue[3]
lm(RT ~ condition +req_action +OutValence, data=tus)



#banova!!!!!!!! - not working atm
# Making sure JAGS is installed
# It can be downloaded here http://mcmc-jags.sourceforge.net (the size is only 2.3 MB)

BANOVA::BANOVA.run (correct ~ req_action, ~condition*req_action, data=df, model_name = 'Binomial', id = 'ID',
                        as.integer(16), num_trials = as.integer(20), iter = 100, thin = 5, chains = 2)
```

#RTs

 #Log
```{r}
library(moments)
skewness(tus$RT, na.rm = TRUE)
# Add a small constant to the data
small_constant <- 0.0001  # Adjust as needed
# Add a small constant to the RT column
tus$RT <- tus$RT + small_constant




    #log10(max(x+1) - x) #for negatively skewed data --> lm_test_nogo %>% mutate(log_rt = log10(max(rt + 1) - rt))
    #log10(x) for positively skewed data,
tus <- tus %>%
  mutate(log_RT = log10(RT));view(tus)


```
       
       
       


#fit-and-bic equivalent of stepAIC for lmer
```{r}
# Function to create all combinations of predictors including interactions up to four variables
get_combinations <- function(predictors) {
  n <- length(predictors)
  combs <- unlist(lapply(1:n, function(i) combn(predictors, i, simplify = FALSE)), recursive = FALSE)
  
  # Generate combinations with interactions up to four variables
  interactions_4way <- lapply(1:(n-3), function(i) {
    combn(predictors, i, FUN = function(x) {
      remaining <- setdiff(predictors, x)
      combs <- combn(remaining, 3, paste, collapse = "*")
      paste(x, combs, sep = "*")
    })
  })
  
  interactions_4way <- unlist(interactions_4way, recursive = FALSE)
  
  c(combs, interactions_4way)
}

# Function to fit models and compute BIC, excluding redundant models
fit_and_bic <- function(data, response, predictors) {
  combinations <- get_combinations(predictors)
  bics <- numeric(length(combinations))
  
  for (i in seq_along(combinations)) {
    formula <- as.formula(paste(response, "~", paste(combinations[[i]], collapse = " + "), "+ (1|ID)"))
    model <- lmer(formula, data = data, REML = FALSE)
    bics[i] <- BIC(model)
  }
  
  result <- data.frame(Model = sapply(combinations, paste, collapse = " + "), BIC = bics)
  result <- result[order(result$BIC), ]
  
  # Remove redundant models
  result <- result[!duplicated(lapply(strsplit(result$Model, "\\+"), function(x) sort(trimws(x)))), ]
  
  result
}

# Define your response variable and predictor variables
response_var <- "RT"
predictor_vars <- c("OutValence", "req_action", "condition", "trial_number")

# Example usage
result <- fit_and_bic(data = tus, response = response_var, predictors = predictor_vars)
print(result)
```


#comparing between three model. This looks to be the best "model_rt_tn" (model 2 and 3)
```{r}
tus$req_action <- relevel(tus$req_action, ref = "noGo")

model_rt1 <- lmer(log_RT ~ req_action*OutValence*condition +(1|ID), data  = tus, REML = FALSE) 
summary (model_rt1) 

model_rt2 <- lmer(log_RT ~ OutValence*req_action*condition*trial_number +(1|ID), data  = tus, REML = FALSE) 
summary (model_rt2)#T

#model_rt_tnsn<- lmer(RT ~ req_action*OutValence*condition*trial_number*session +(1|ID), data  = tus, REML = FALSE) 
#summary (model_rt_tnsn) # NO

model_rt3 <- lmer(log_RT ~ OutValence*req_action*condition +trial_number +(1|ID), data  = tus, REML = FALSE) 
summary (model_rt3) # good - this one probably

model_rt4 <- lmer(log_RT ~ req_action*OutValence*condition +  condition*trial_number +(1|ID), data  = tus, REML = FALSE) 
summary (model_rt4) #good too

model_rt5 <- lmer(log_RT ~ req_action*OutValence +  condition*trial_number +(1|ID), data  = tus, REML = FALSE) 
summary (model_rt5)#

model_rt6 <- lmer(log_RT ~ Cue*condition + trial_number +(1|ID), data  = tus, REML = FALSE) 
summary (model_rt6)#

model_rt7 <- lmer(log_RT ~ condition + OutValence + req_action +trial_number +(1|ID), data  = tus, REML = FALSE) 
summary (model_rt7)# main effects
   
# Perform Likelihood Ratio Test
lr_test <- anova(model_rt1, model_rt2, model_rt3, model_rt4, model_rt5, model_rt6, model_rt7)
print(lr_test) 
p_value <- lr_test$Pr[2];p_value
```

#anovaBF for RTs
predictors with + :  effects are assumed to be additive and independent of each other.
predictors with * :  possibility the effect of one predictor on the outcome variable may vary depending on the level of another predictor -aptures the synergistic or conditional effects of predictors 
```{r}
#run anovaBF IV = req_action and condition
# Calculate Bayes factors with specified number of iterations
rt_1 <- anovaBF( formula = log_RT ~ condition*Cue + ID, data = df,  whichRandom = "ID", progress = FALSE, iterations = 3000); summary (rt_1) # refers to the number of Monte Carlo samples used for approximation when computing Bayes factors. It specifies the number of samples used to estimate the marginal likelihoods of the models being compared.each iteration corresponds to one random sample drawn from the posterior distribution. By increasing the number of iterations, you obtain a more accurate approximation of the integral, leading to more precise estimates of the marginal likelihoods and, consequently, more reliable Bayes factors for model comparison. "Iterations" refers to the number of times the computer repeats a specific calculation to make sure it's accurate.unning a simulation or experiment. By doing it multiple times (more iterations), we can get a more reliable answer.
rt_1_inter<-rt_1[4]/rt_1[3]; summary(rt_1_inter) #2.299506 ±2.95% #large variation that's why I used iterations above




rt_2<-anovaBF(log_RT ~ condition*Cue*block  + ID, data = df, whichRandom = "ID",
   progress=FALSE, iterations = 3000); summary (rt_2)
rt_2[10]/rt_2[4] 


 rt <-anovaBF(log_RT ~ req_action*OutValence*condition  + ID, data = df, whichRandom = "ID",
   progress=FALSE)
rt[17]/rt[13] 
 rt[18]/rt[13] 
 rt[18]/rt[17] 
summary(rt)
ratios<-rt/max(rt);ratios#best models as denominator to so the closest ones 13, 14, 15, 17, 18, 16, 12, 11



#or
# Remove rows with missing values in 'RT'
tus <- na.omit(tus)
# Convert 'ID' to factor if it's not already a factor
if (!is.factor(tus$ID)) {
  tus$ID <- as.factor(tus$ID)
}

# Calculate Bayes factors for each model using the 'tus' dataset
bf_13 <- lmBF(log_RT ~ req_action + OutValence + req_action:OutValence + ID, data = tus, whichRandom = "ID")
bf_15 <- lmBF(log_RT ~ condition + req_action + condition:req_action + OutValence + req_action:OutValence + condition:req_action:OutValence + ID, data = tus, whichRandom = "ID")
bf_17 <- lmBF(log_RT ~ condition + req_action + condition:req_action + OutValence + condition:OutValence + req_action:OutValence + ID, data = tus, whichRandom = "ID")
bf_18 <- lmBF(log_RT ~ condition + req_action + condition:req_action + OutValence + condition:OutValence + req_action:OutValence + condition:req_action:OutValence + ID, data = tus, whichRandom = "ID")

# Extract Bayes factors
bf_values <- c(bf_13, bf_15, bf_17, bf_18)

# Compare Bayes factors
bf_values / max(bf_values)

```



#Reporting -  examples
```{r}
summ(model_acc, exp = T)# set "exp = T" to show esponentiated estimates; if you need standardised estimaets, set "scale = T"
summ(model_acc, scale = T)
report(model_acc)
report(model_acc) %>% summary()
report_table(model_acc)
report_performance(model_acc)
report_parameters(model_acc)
```
 
###########################################################################################################################################################################




#lspline #knots #learning curve
Piecewise Linear Regression (Learning and Exploitation Phases)


outcome:
1. A linear component captures linear trends or patterns in the data. For example, if there is a constant increase or decrease in RT as trial_number increases, the linear component would capture this trend.
2. A quadratic component captures nonlinear trends or patterns in the data. For example, if RT initially decreases and then increases (or vice versa) as trial_number increases, the quadratic component would capture this curvature.

```{r}
# Identify the trial number where the learning curve starts to plateau
plateau_trial <- 22

# Subset data for before and after the plateau
before_plateau <- tus[tus$trial_number <= plateau_trial, ]
after_plateau <- tus[tus$trial_number > plateau_trial, ]
```



It seems that condition plays an important role especially after the learning curve starts to plateau, mainly for the Accuracy. (when interaction with trial_number)
```{r}


# Create an interaction term between trial_number, condition, and block for before_plateau
before_plateau$interaction_term <- interaction(before_plateau$trial_number, before_plateau$condition, drop = TRUE)
 
#Create an interaction term between trial_number, condition, and block for after_plateau
after_plateau$interaction_term <- interaction(after_plateau$trial_number, after_plateau$condition, drop = TRUE)
#######################      Accuracy - correct     ###########################



# Fit GLMM for correct before plateau
glmer_before <- glmer(correct ~ poly(interaction_term, degree = 2) + (1 | ID), data = before_plateau, family = binomial)


# Fit GLMM for correct after plateau
glmer_after <- glmer(correct ~ poly(interaction_term, degree = 2) + (1 | ID), data = after_plateau, family = binomial)

# Print summaries of the models
summary(glmer_before)
summary(glmer_after)

######################        RTs                   ##########################


# Fit linear mixed-effects regression model for RT before plateau
lmer_before <- lmer(RT ~ poly(interaction_term, degree = 2) + (1 | ID), data = before_plateau)


# Fit linear mixed-effects regression model for RT after plateau
lmer_after <- lmer(RT ~ poly(interaction_term, degree = 2)  + (1 | ID), data = after_plateau)

# Print summaries of the models
summary(lmer_before)
summary(lmer_after)

```

#interaction RT*condition & correct*condition


correct*condition = significant even in exploitation phase

```{r}
#RT

# Create interaction terms between RT and condition for before_plateau
before_plateau$RT_condition <- interaction(before_plateau$RT, before_plateau$condition, drop = TRUE)

# Create interaction terms between RT and condition for after_plateau
after_plateau$RT_condition <- interaction(after_plateau$RT, after_plateau$condition, drop = TRUE)

#Fit GLMM for RT before plateau
glmer_before_RT <- glmer(RT ~ poly(RT_condition, degree = 2) + (1 | ID), data = before_plateau, family = gaussian)

# Fit GLMM for RT after plateau
glmer_after_RT <- glmer(RT ~ poly(RT_condition, degree = 2) + (1 | ID), data = after_plateau, family = gaussian)


# Print summaries of the models for RT
summary(glmer_before_RT)
summary(glmer_after_RT)


#Accuracy
# Create interaction terms between correct and condition for before_plateau
before_plateau$correct_condition <- interaction(before_plateau$correct, before_plateau$condition, drop = TRUE)

# Create interaction terms between correct and condition for after_plateau
after_plateau$correct_condition <- interaction(after_plateau$correct, after_plateau$condition, drop = TRUE)

# Fit GLMM for correct before plateau
glmer_before_correct <- glmer(correct ~ poly(correct_condition, degree = 2) + (1 | ID), data = before_plateau, family = binomial) #SIGNIFICANT

# Fit GLMM for correct after plateau
glmer_after_correct <- glmer(correct ~ poly(correct_condition, degree = 2) + (1 | ID), data = after_plateau, family = binomial) #SIGNIFICANT!!!!

#
# Print summaries of the models for correct
summary(glmer_before_correct)
summary(glmer_after_correct)



```

for accuracy*condition above which is significant, I am specifying the levels - Icannot
```{r}



```


subsetting before and after, when plateau

```{r}
# Identify the trial number where the learning curve starts to plateau
plateau_trial <- 20


# Subset data for before and after the plateau
before_plateau <- tus[tus$trial_number <= plateau_trial, ]
after_plateau <- tus[tus$trial_number > plateau_trial, ]
```


CONDITION
```{r}
# Fit linear mixed-effects regression model for RT before plateau
lmer_before_RT <- lmer(RT ~  condition + (1 | ID), data = before_plateau)

# Fit generalized linear mixed-effects regression model for correct before plateau
glmer_before_correct <- glmer(correct ~  condition + (1 | ID), family = binomial, data = before_plateau)

# Fit linear mixed-effects regression model for RT after plateau
lmer_after_RT <- lmer(RT ~  condition + (1 | ID), data = after_plateau)

# Fit generalized linear mixed-effects regression model for correct after plateau
glmer_after_correct <- glmer(correct ~  condition + (1 | ID), family = binomial, data = after_plateau) # dacc *** ai *

# Print summaries of the models
summary(lmer_before_RT)
summary(glmer_before_correct)
summary(lmer_after_RT)
summary(glmer_after_correct)


```


CONDITION*CUE


```{r}

# Fit linear mixed-effects regression model for RT before plateau
lmer_before_RT_cond*Cue <- lmer(RT ~  condition*Cue + (1 | ID), data = before_plateau)

# Fit generalized linear mixed-effects regression model for correct before plateau
glmer_before_correct_cond*Cue <- glmer(correct ~   condition*Cue  + (1 | ID), family = binomial, data = before_plateau)

# Fit linear mixed-effects regression model for RT after plateau
lmer_after_RT_cond*Cue <- lmer(RT ~   condition*Cue  + (1 | ID), data = after_plateau)

# Fit generalized linear mixed-effects regression model for correct after plateau
glmer_after_correct_cond*Cue  <- glmer(correct ~   condition*Cue  + (1 | ID), family = binomial, data = after_plateau) # dacc *** ai *

# Print summaries of the models
summary(lmer_before_RT_cond*Cue)
summary(glmer_before_correct_cond*Cue)
summary(lmer_after_RT_cond*Cue)
summary(glmer_after_correct_cond*Cue)

```



CONDITION*VALENCE
```{r}

# Fit linear mixed-effects regression model for RT before plateau
lmer_before_RT_con_val <- lmer(RT ~  condition*OutValence + (1 | ID), data = before_plateau)

# Fit generalized linear mixed-effects regression model for correct before plateau
glmer_before_correct_con_val <- glmer(correct ~  condition*OutValence  + (1 | ID), family = binomial, data = before_plateau)

# Fit linear mixed-effects regression model for RT after plateau
lmer_after_RT_con_val <- lmer(RT ~  condition*OutValence  + (1 | ID), data = after_plateau)

# Fit generalized linear mixed-effects regression model for correct after plateau
glmer_after_correct_con_val  <- glmer(correct ~   condition*OutValence + (1 | ID), family = binomial, data = after_plateau) 

# Print summaries of the models
summary(lmer_before_RT_con_val)
summary(glmer_before_correct_con_val)
summary(lmer_after_RT_con_val)
summary(glmer_after_correct_con_val)
```



CONDITION*BLOCK (it only makes sense if we set the knot on 80 (first block or play around it))
```{r}

# Identify the trial number where the learning curve starts to plateau
plateau_trial <- 80


# Subset data for before and after the plateau
before_plateau <- tus[tus$trial_number <= plateau_trial, ]
after_plateau <- tus[tus$trial_number > plateau_trial, ]



# Fit linear mixed-effects regression model for RT before plateau
lmer_before_RT_con_block <- lmer(RT ~  condition*block + (1 | ID), data = before_plateau)

# Fit generalized linear mixed-effects regression model for correct before plateau
glmer_before_correct_con_block <- glmer(correct ~  condition*block  + (1 | ID), family = binomial, data = before_plateau)

# Fit linear mixed-effects regression model for RT after plateau
lmer_after_RT_con_block <- lmer(RT ~  condition*block  + (1 | ID), data = after_plateau)

# Fit generalized linear mixed-effects regression model for correct after plateau
glmer_after_correct_con_block <- glmer(correct ~ condition*block + (1 | ID), family = binomial, data = after_plateau) 

# Print summaries of the models
summary(lmer_before_RT_con_block)
summary(glmer_before_correct_con_block)
summary(lmer_after_RT_con_block)
summary(glmer_after_correct_con_block)
```


OutValence * req_action * condition (not much sense but significant results if you change know according to diagram)
-when Go as reference more significant results
```{r}

# Identify the trial number where the learning curve starts to plateau
plateau_trial <- 23


# Subset data for before and after the plateau
before_plateau <- tus[tus$trial_number <= plateau_trial, ]
after_plateau <- tus[tus$trial_number > plateau_trial, ]

# If it's not a factor, convert it to a factor
if (!is.factor(before_plateau$req_action)) {
  before_plateau$req_action <- as.factor(before_plateau$req_action)
}

if (!is.factor(after_plateau$req_action)) {
  after_plateau$req_action <- as.factor(after_plateau$req_action)
}
# Now, relevel req_action with "noGo" as the reference level
before_plateau$req_action <- relevel(before_plateau$req_action, ref = "noGo")
after_plateau$req_action <- relevel(after_plateau$req_action, ref = "noGo")


# Fit linear mixed-effects regression model for RT before plateau
lmer_before_RT_vrc <- lmer(RT ~  OutValence * req_action * condition + (1 | ID), data = before_plateau)

# Fit generalized linear mixed-effects regression model for correct before plateau
glmer_before_correct_vrc <- glmer(correct ~  OutValence * req_action * condition  + (1 | ID), family = binomial, data = before_plateau)

# Fit linear mixed-effects regression model for RT after plateau
lmer_after_RT_vrc <- lmer(RT ~  OutValence * req_action * condition  + (1 | ID), data = after_plateau)

# Fit generalized linear mixed-effects regression model for correct after plateau
glmer_after_correct_vrc <- glmer(correct ~ OutValence * req_action * condition + (1 | ID), family = binomial, data = after_plateau) 

# Print summaries of the models
summary(lmer_before_RT_vrc)
summary(glmer_before_correct_vrc)
summary(lmer_after_RT_vrc)
summary(glmer_after_correct_vrc)
```


























          #from here ONWARDS, IT CAN BE IGNORED AT THE MOMENT - DECIDE IF NEEDED
          
          #Cue  - not needed
```{r}
model_rt_cue <- lmer(log_RT ~ Cue*condition +(1|ID) , 
                 data  = tus,REML = FALSE) #REML = FALSE
summary (model_rt_cue)

#anovaBF IV = Cue - interaction between the Cue and the condition
rt_cue <-anovaBF(log_RT ~ Cue*condition  + ID, data = df, whichRandom = "ID",
   progress=FALSE)
rt_cue[4]/rt_cue[3]
summary(rt_cue)
```

  # ANALYSIS FOR SALIENT ONLY (EXCLUDE NEUTRAL OUTCOME)
  
```{r}
#select salient only (win, lose) and keep variables ID through block and all columns between them
tus_salient <- subset(tus, salient=!"neutral",
select=ID:salient);  

salient_df <-tus_salient %>% drop_na();  View(salient_df) # WRONG IT DRPOPS ACC AS WELL
```  

        
## Accuracy
```{r}
model_acc_sal <- glmer(correct ~ condition + req_action + trial_number + OutValence*condition + req_action*condition +(1|ID) , 
                 data  = salient_df, family="binomial", 
                 glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000))) #REML = FALS
summary(model_acc_sal)

#Cue impact - not good
sal_cue_accu <- glmer(correct ~ Cue*condition*trial_number +(1|ID) , 
                 data  = salient_df, family="binomial", 
                 glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000))) #REML = FALSE
summary (sal_cue_accu) 
```

## RTs
```{r}
model_rt_sal <- lmer(log_RT ~ req_action  + trial_number + OutValence*condition + req_action*condition+(1|ID), 
                 data  = salient_df, REML = FALSE) #REML = FALSE
summary (model_rt_sal) 
report_table(model_rt_sal)
#Cue impact -that is good
sal_cue_rt <- lmer(log_RT ~ Cue*condition +(1|ID), 
                 data  = salient_df, REML = FALSE) #REML = FALSE
summary (sal_cue_rt) 
```


 ##Analysis with Bayesian binomial/logistic anova for the categorical DV - "correct"
      # with rstarm + bridging

```{r}

library(htmltools)
options(mc.cores = 4)


cor.m1.stan <- rstanarm::stan_glmer(correct ~ condition * OutValence * req_action * Cue + (1|ID),  weights=trial_number,
                 data  = tus, family="binomial", chains=4, iter=2e4, 
                diagnostic_file = "__df1.csv") #deleted the "weights = ..."

cor.m1.0.stan <- rstanarm::stan_glmer(correct ~ (condition + OutValence + req_action) * Cue + (1|ID), weights=trial_number,
               data  = tus, family="binomial", chains=4, iter=2e4, 
                diagnostic_file = "__df0.csv") #notsure if this the base model. #deleted the "weights = ..."

bridge_1 <-bridgesampling::bridge_sampler(cor.m1.stan)
bridge_0 <- bridgesampling::bridge_sampler(cor.m1.0.stan)
# BW: this gives evidence (or not) for the interaction
bayes_factor(bridge_1, bridge_0, log = FALSE)



##model with no interaction 
acc.m2.stan <- rstanarm::stan_glmer(is_slip ~ condition * Cue + (1|ID), 
               data  = elm_test.byblock, family="binomial", chains=4, iter=2e4, 
                diagnostic_file = "__df2.csv")

acc.m3.0.stan <- rstanarm::stan_glmer(is_slip ~ condition + Cue + (1|ID), 
                weights=exposure, data  = elm_test.byblock, family="binomial", chains=4, iter=2e4, 
                diagnostic_file = "__df2.0.csv")

bridge_3 <-bridgesampling::bridge_sampler(acc.m2.stan)
bridge_3.0 <- bridgesampling::bridge_sampler(acc.m3.0.stan)


# evidence
bayes_factor(bridge_3, bridge_3.0, log = FALSE)

```

