---
title: "GNG_TUS_Study_1_320trials_PROCESSING"
author: "nomi"
date: "2023-10-31"
output: html_document
---


#Load libraries
```{r}
library(readr)
library(tibbletime)
library(purrr)
library(stringr)
library(report)
library(ggplot2)
library(dplyr)
library(tidyverse)
library(patchwork)
library(ggpubr)
library(yarr)
library (yarrr)
library(afex)
#install.packages("devtools")
#devtools::install_github("mikabr/ggpirate")
library(ggpirate)
```


#READ FILE
```{r setup, include=FALSE}
tus <- read_csv("GNG_TUS_S1.csv")
tus_filtered<- read_csv ("GNG_tus_filtered_S1.csv")
```


 #PROCESSING


## MEAN RT - PRESSES 
```{r}
tus_presses <- subset(tus_filtered, RT != "0") # exlude 0s (no presses)
RT_presses <-tus_clean_allexs%>%  group_by(condition) %>% 
  summarise(Mean_RT = mean(RT, na.rm = TRUE))
RT_presses_many_variables <-tus_presses %>%  group_by(condition, req_action, correct, response) %>% 
  summarise(Mean_RT = mean(RT, na.rm = TRUE))
```

## MEAN CORRECT
```{r}
correct_res <-tus_filtered%>%  group_by(condition, ID) %>% 
  summarise(correct = mean(correct))
RT_presses_many_variables <-tus_presses %>%  group_by(condition, req_action, correct, response) %>% 
  summarise(Mean_RT = mean(RT, na.rm = TRUE))
```

## Distribution of RT
```{r}
tus_presses <- subset(tus_filtered, RT != "0") # exlude 0s (no presses)
RT_presses <-tus_presses%>%  group_by(RT, ID) %>% 
  summarise(Mean_RT = mean(RT, na.rm = TRUE));RT_presses #%>%
ggplot(data = RT_presses, 
       aes(x = Mean_RT)) + 
  geom_histogram()+ ggtitle ("Distribution of RT for presses") 

# Rename columns, keep press only
MeanRTpersub <- tus_filtered %>% 
  filter(response == "press") %>%
  group_by(Cue, ID, Action = req_action, Valence = OutValence, condition) %>% 
  summarise(RT = mean(RT))
# Plot (needs to be shrinked V in valence does not show)
yarrr::pirateplot(formula = RT ~ Action + Valence + condition,    # DV = reaction time, IV1 = required action, IV2 = outcome valence
                  data = MeanRTpersub,           
                  theme = 2,
                  # main = "Condition",
                  ylab = "Reaction Time (ms)",
                  ylim = c(400, 1000),
                  bean.f.o = .4, # Bean fill
                  bean.b.o = .2, # Light bean border
                  point.o = .5, # Points (opacity)
                  inf.disp = "line",
                  inf.f.o = 0.8, # Inference fill
                  inf.b.o = 0.8, # Inference border
                  avg.line.o = 0, # Average line
                  point.pch = 21,
                  point.bg = "white",
                  point.cex = .5) 
```



      #plot (IES_by_cond_cue) - if the pre-processing code is correct
```{r}
# Summarize by condition
IES_by_cond_cue_id<- tus_filtered %>%
  group_by(ID, condition, Cue) %>%
  summarise(
    mean_IES = mean(IES, na.rm = TRUE),  # Calculate the mean IES for each condition
    sd_IES = sd(IES, na.rm = TRUE),  # Calculate the standard deviation of the IES for each condition
    n = n()  # Count the number of observations for each condition
  )

IES_by_cond_cue<- IES_by_cond_cue_id %>%
  group_by(condition, Cue) %>%
  summarise(
    mean_IES = mean(mean_IES, na.rm = TRUE),  # Calculate the mean IES for each condition
    sd_IES = sd(sd_IES, na.rm = TRUE),  # Calculate the standard deviation of the IES for each condition
    n = n()  # Count the number of observations for each condition
  )

print(IES_by_cond_cue) #done by ID first - this one is good

# Filter data for cues GW and GAL
GW_GAL_data <- filter(IES_by_cond_cue, Cue %in% c("GW", "GAL"))

# Create plot for cues GW and GAL
plot_GW_GAL <- ggplot(GW_GAL_data, aes(x = condition, y = mean_IES, fill = Cue)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_errorbar(aes(ymin = mean_IES - sd_IES, ymax = mean_IES + sd_IES), width = 0.2, position = position_dodge(0.9)) +
  labs(title = "Mean IES for Go Cues by Condition",
       x = "Condition",
       y = "Mean IES",
       fill = "Cue") +
  theme_minimal() +
  coord_cartesian(ylim = c(400, NA)) +
 facet_wrap(~ Cue, scales = "free_y")

# Filter data for cues NGW and NGL
NGW_NGL_data <- filter(IES_by_cond_cue, Cue %in% c("NGW", "NGL"))

# Create plot for cues NGW and NGL
plot_NGW_NGL <- ggplot(NGW_NGL_data, aes(x = condition, y = mean_IES, fill = Cue)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_errorbar(aes(ymin = mean_IES - sd_IES, ymax = mean_IES + sd_IES), width = 0.2, position = position_dodge(0.9)) +
  labs(title = "Mean IES for noGo Cues by Condition",
       x = "Condition",
       y = "Mean IES",
       fill = "Cue") +
  theme_minimal() +
  coord_cartesian(ylim = c(0, NA))+
 facet_wrap(~ Cue, scales = "free_y")

# Display plots
plot_GW_GAL
plot_NGW_NGL



#plot IES by condition only
   #no, plot is not good or correct as sd is from 0.001 for ngw cues to high. so better seperate by go vs nogo cues
```
 




## Proportion of GO response per condition 

          #smooth
```{r}
# compute proportion of go responses for each participant (first sum per ID, then feed that into general summary)
MeanGoResppersub <- tus_filtered %>% group_by(ID, Cue, req_action, OutValence, block, TrialCount) %>% summarise(GoResponse = mean(GoResponse))
MeanGoResppersub <- na.omit(MeanGoResppersub)
MeanGoResp <- MeanGoResppersub %>% group_by(Cue, req_action, block, OutValence, TrialCount) %>% summarise(GoResponse = mean(GoResponse))

  
# Plot of p(Go) responses
ggplot(MeanGoResp) + 
  geom_smooth(aes(TrialCount, GoResponse, colour = OutValence, lty = req_action)) +
  scale_colour_brewer(palette = "Set1") +
  labs(y = "p(GO)", x = "Trial", title = "Trial-by-trial behaviour") +
  scale_x_continuous(breaks = seq(1, 20, by = 1)) +  # Set breaks manually
  theme_bw()

# Plot of p(Go) responses per block
ggplot(MeanGoResp) + 
  geom_smooth(aes(TrialCount, GoResponse, colour = OutValence, lty = req_action)) +
  scale_colour_brewer(palette = "Set1") +
  facet_grid(~block) +
  labs(y = "p(GO)", x = "Trial", title = "Trial-by-trial behaviour") +
  scale_x_continuous(breaks = seq(1, 20, by = 1)) +  # Set breaks manually
  theme_bw()

```
     
     
     #raw trial_by_trial
     
```{r}
#raw trial-by-trial
 meango <- tus_filtered %>% 
  group_by(Cue, req_action, OutValence, TrialCount) %>% 
 summarise(GoResponse = mean(GoResponse))

# Summarize data to calculate mean and CIs
meango <- meango %>%
  group_by(TrialCount, OutValence, req_action) %>%
  summarise(
    GoResponse = mean(GoResponse),
    n = n(),
    se = ifelse(n > 1, sd(GoResponse) / sqrt(n), 0.1),  # Adjusted to assume a fixed SE for small groups
    lower_ci = ifelse(n > 1, GoResponse - qt(1 - 0.05 / 2, n - 1) * se, GoResponse - 0.2),
    upper_ci = ifelse(n > 1, GoResponse + qt(1 - 0.05 / 2, n - 1) * se, GoResponse + 0.2)
  ) %>%
  ungroup()

ggplot(meango, aes(x = TrialCount, y = GoResponse, colour = OutValence, linetype = req_action)) + 
  geom_line() +
  geom_point() +
  geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci, fill = OutValence), alpha = 0.05, colour = NA) +
  scale_colour_brewer(palette = "Set1") +
  scale_fill_brewer(palette = "Set1") +
  labs(y = "p(GO)", x = "Trial", title = "Trial-by-trial behaviour") +
  scale_x_continuous(breaks = seq(1, 20, by = 1)) +  # Set breaks manually
  #xlim(1, 20) +  # Ensures the plot starts from 1
  theme_bw()





#raw per block
# Summarize data to calculate mean and CIs
 meangob <- tus_filtered %>% 
  group_by(Cue, req_action, block, OutValence, TrialCount) %>% 
 summarise(GoResponse = mean(GoResponse))

 meangob <- meangob %>%
  group_by(TrialCount, block, OutValence, req_action) %>%
  summarise(
    GoResponse = mean(GoResponse),
    n = n(),
    se = ifelse(n > 1, sd(GoResponse) / sqrt(n), 0.1),  # Adjusted to assume a fixed SE for small groups
    lower_ci = ifelse(n > 1, GoResponse - qt(1 - 0.05 / 2, n - 1) * se, GoResponse - 0.2),
    upper_ci = ifelse(n > 1, GoResponse + qt(1 - 0.05 / 2, n - 1) * se, GoResponse + 0.2)
  ) %>%
  ungroup()

ggplot(meangob, aes(x = TrialCount, y = GoResponse, colour = OutValence, linetype = req_action)) + 
  geom_line(aes(group = interaction(OutValence, req_action))) +
  geom_point() +
  geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci, fill = OutValence), alpha = 0.05, colour = NA) +
  scale_colour_brewer(palette = "Set1") +
  scale_fill_brewer(palette = "Set1") +
  facet_grid(~ block) +  # Ensure `block` is included in facet_grid()
  labs(y = "p(GO)", x = "Trial", title = "Trial-by-trial behaviour") +
    scale_x_continuous(breaks = seq(1, 20, by = 1)) +  # Set breaks manually
 # xlim(1, 20) +  # Ensures the plot starts from 1
  theme_bw()
```
     
     
     
    
## Session 
### It seems to be significant. In the first session they do worse.
```{r}
# Compute proportion of correct responses for each participant
tus_correct_sub <- tus_filtered %>%
    group_by(ID, OutValence, session, condition, req_action) %>%
    summarise(correct = mean(correct, na.rm = TRUE), .groups = "drop")

# Compute mean proportion of correct responses
tus_correct <- tus_correct_sub %>%
  group_by(OutValence, session, req_action, condition) %>%
  summarise(correct = mean(correct, na.rm = TRUE), .groups = "drop")

# Re-ordering levels to show as 1, 2, 3 in the x-axis
tus_correct$session <- factor(tus_correct$session, levels = c("1", "2", "3"))

# Plot session using pirateplot
pirateplot(formula = correct ~ session + condition,
           data = tus_correct,
           ylim = c(0.3, 1.05), # Adjust the y-axis limits
           theme = 0,
           bean.f.o = .7, # Bean fill
           point.o = .3, # Points
           inf.f.o = .3, # Inference fill
           inf.b.o = .8, # Inference border
           avg.line.o = 1, # Average line
           bar.f.o = .5, # Bar
           inf.f.col = "white", # Inf fill color
           inf.b.col = "black", # Inf border color
           avg.line.col = "black", # Avg line color
           point.pch = 21,
           point.bg = "white",
           point.col = "black",
           point.cex = .7)

#boxplot
ggplot(tus_correct, aes(x = session, y = correct, fill = condition)) +
  geom_boxplot() +
  geom_jitter ()#(position = position_jitter(width = 0.2), size = 2, alpha = 0.5, color = "black", fill = "black") + 
  labs(y = "Proportion Correct", x = "Session", title = "Proportion of Correct Responses by Session and Condition") +
  scale_fill_brewer(palette = "Set1") +
  theme_bw() +
coord_cartesian(ylim = c(0.5, 1)) # Adjust y-axis limits






# Plot session using pirateplot without "condition"
pirateplot(formula = correct ~ session,
           data = tus_correct,
           ylim = c(0.5, 0.95), # Adjust the y-axis limits
           theme = 0,
           bean.f.o = .7, # Bean fill
           point.o = .3, # Points
           inf.f.o = .3, # Inference fill
           inf.b.o = .8, # Inference border
           avg.line.o = 1, # Average line
           bar.f.o = .5, # Bar fill
           bar.b.o = 0.2, # Bar border width (adjust to make bars thinner)
           inf.f.col = "white", # Inf fill color
           inf.b.col = "black", # Inf border color
           avg.line.col = "black", # Avg line color
           point.pch = 21,
           point.bg = "white",
           point.col = "black",
           point.cex = .7)
#boxplot
ggplot(tus_correct, aes(x = session, y = correct)) + #fill = session
  geom_boxplot() +
  geom_jitter ()#(position = position_jitter(width = 0.2), size = 2, alpha = 0.5, color = "black", fill = "black") + 
  labs(y = "Proportion Correct", x = "Session", title = "Proportion of Correct Responses by Session") +
  scale_fill_brewer(palette = "Set3") +
  theme_bw() +
coord_cartesian(ylim = c(0.5, 1)) # Adjust y-axis limits
```


#proportion of GO response per type of Stimulation (sham, ai, dACC) 
```{r}
    #AI - 
ai <- subset(tus_filtered, condition == "c.ai")

# compute proportion of go responses for each participant
MeanGoResppersub_ai <- ai %>% group_by(ID, Cue, req_action, OutValence, TrialCount) %>% summarise(GoResponse = mean(GoResponse))

MeanGoResp.ai <- MeanGoResppersub_ai %>% group_by(Cue, req_action, OutValence, TrialCount) %>% summarise(GoResponse = mean(GoResponse))

#plot
ai_rolavg<- ggplot(MeanGoResp.ai) + 
  geom_smooth(aes(TrialCount, GoResponse,colour=OutValence, lty = req_action)) +
  scale_colour_brewer(palette = "Set1") +
  labs(y = "p(GO)", x = "Trial", title = "Trial-by-trial behaviour for AI") +
   xlim(NA, 20)+
 theme_bw() 


    #dACC - 
dacc <- subset(tus_filtered, condition == "b.dacc")
#dacc <- na.omit(dacc)

# compute proportion of go responses for each participant
MeanGoResppersub_dacc <- dacc %>% group_by(ID, Cue, req_action, OutValence, TrialCount) %>% summarise(GoResponse = mean(GoResponse))
MeanGoResp.dacc <- MeanGoResppersub_dacc %>% group_by(Cue, req_action, OutValence, TrialCount ) %>% summarise(GoResponse = mean(GoResponse))

#plot
dacc_rolavg<- ggplot(MeanGoResp.dacc) + 
  geom_smooth(aes(TrialCount, GoResponse,colour=OutValence, lty = req_action)) +
  scale_colour_brewer(palette = "Set1") +
  labs(y = "p(GO)", x = "Trial", title = "Trial-by-trial behaviour for dACC")+
   xlim(NA, 20)+ theme_bw() 



    #Sham
sham <- subset(tus_filtered, condition == "a.sham")

# compute proportion of go responses for each participant
MeanGoResppersub_sham <- sham %>% group_by(ID, Cue, req_action, OutValence, TrialCount) %>% summarise(GoResponse = mean(GoResponse))

MeanGoResp.sham <- MeanGoResppersub_sham %>% group_by(Cue, req_action, OutValence, TrialCount) %>% summarise(GoResponse = mean(GoResponse))

#plot
sham_rolavg<- ggplot(MeanGoResp.sham) + 
  geom_smooth(aes(TrialCount, GoResponse,colour=OutValence, lty = req_action)) +
  scale_colour_brewer(palette = "Set1") +
  labs(y = "p(GO)", x = "Trial", title = "Trial-by-trial behaviour for sham") +
   xlim(NA, 20)+
 theme_bw() 

#roll avg per CONDITION
rol_avg <- ggarrange(sham_rolavg, ai_rolavg, dacc_rolavg,
                    #labels = c("GW", "GAL", "NGW", "NGL"), 
                  ncol = 2, nrow = 2);rol_avg
```



      #proportion of GO response per type of Stimulation (sham, ai, dACC) - RAW

```{r}
#AI - 
ai <- subset(tus_filtered, condition == "c.ai")

# compute proportion of go responses for each participant
# Summarize data to calculate mean and CIs
 mean_ai <- ai %>% 
  group_by(Cue, req_action, OutValence, TrialCount) %>% 
 summarise(GoResponse = mean(GoResponse))

 meango_ai <- mean_ai %>%
  group_by(TrialCount, OutValence, req_action) %>%
  summarise(
    GoResponse = mean(GoResponse),
    n = n(),
    se = ifelse(n > 1, sd(GoResponse) / sqrt(n), 0.1),  # Adjusted to assume a fixed SE for small groups
    lower_ci = ifelse(n > 1, GoResponse - qt(1 - 0.05 / 2, n - 1) * se, GoResponse - 0.2),
    upper_ci = ifelse(n > 1, GoResponse + qt(1 - 0.05 / 2, n - 1) * se, GoResponse + 0.2)
  ) %>%
  ungroup()
#plot
pai<-ggplot(meango_ai, aes(x = TrialCount, y = GoResponse, colour = OutValence, linetype = req_action)) + 
  geom_line(aes(group = interaction(OutValence, req_action))) +
  geom_point() +
  geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci, fill = OutValence), alpha = 0.05, colour = NA) +
  scale_colour_brewer(palette = "Set1") +
  scale_fill_brewer(palette = "Set1") +
  labs(y = "p(GO)", x = "Trial", title = "Trial-by-trial behaviour AI") +
    scale_x_continuous(breaks = seq(1, 20, by = 1)) +  # Set breaks manually
 # xlim(1, 20) +  # Ensures the plot starts from 1
  theme_bw()
  


    #dACC - 
dacc <- subset(tus_filtered, condition == "b.dacc")
#dacc <- na.omit(dacc)

# compute proportion of go responses for each participant
# Summarize data to calculate mean and CIs
 mean_dacc <- dacc %>% 
  group_by(Cue, req_action, OutValence, TrialCount) %>% 
 summarise(GoResponse = mean(GoResponse))

 meango_dacc <- mean_dacc %>%
  group_by(TrialCount, OutValence, req_action) %>%
  summarise(
    GoResponse = mean(GoResponse),
    n = n(),
    se = ifelse(n > 1, sd(GoResponse) / sqrt(n), 0.1),  # Adjusted to assume a fixed SE for small groups
    lower_ci = ifelse(n > 1, GoResponse - qt(1 - 0.05 / 2, n - 1) * se, GoResponse - 0.2),
    upper_ci = ifelse(n > 1, GoResponse + qt(1 - 0.05 / 2, n - 1) * se, GoResponse + 0.2)
  ) %>%
  ungroup()
#plot
pdacc<-ggplot(meango_dacc, aes(x = TrialCount, y = GoResponse, colour = OutValence, linetype = req_action)) + 
  geom_line(aes(group = interaction(OutValence, req_action))) +
  geom_point() +
  geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci, fill = OutValence), alpha = 0.05, colour = NA) +
  scale_colour_brewer(palette = "Set1") +
  scale_fill_brewer(palette = "Set1") +
  labs(y = "p(GO)", x = "Trial", title = "Trial-by-trial behaviour dACC") +
    scale_x_continuous(breaks = seq(1, 20, by = 1)) +  # Set breaks manually
 # xlim(1, 20) +  # Ensures the plot starts from 1
  theme_bw()



    #Sham
sham <- subset(tus_filtered, condition == "a.sham")


# compute proportion of go responses for each participant
# Summarize data to calculate mean and CIs
 mean_sham <- sham %>% 
  group_by(Cue, req_action, OutValence, TrialCount) %>% 
 summarise(GoResponse = mean(GoResponse))

 meango_sham <- mean_sham %>%
  group_by(TrialCount, OutValence, req_action) %>%
  summarise(
    GoResponse = mean(GoResponse),
    n = n(),
    se = ifelse(n > 1, sd(GoResponse) / sqrt(n), 0.1),  # Adjusted to assume a fixed SE for small groups
    lower_ci = ifelse(n > 1, GoResponse - qt(1 - 0.05 / 2, n - 1) * se, GoResponse - 0.2),
    upper_ci = ifelse(n > 1, GoResponse + qt(1 - 0.05 / 2, n - 1) * se, GoResponse + 0.2)
  ) %>%
  ungroup()
#plot
psham<-ggplot(meango_sham, aes(x = TrialCount, y = GoResponse, colour = OutValence, linetype = req_action)) + 
  geom_line(aes(group = interaction(OutValence, req_action))) +
  geom_point() +
  geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci, fill = OutValence), alpha = 0.05, colour = NA) +
  scale_colour_brewer(palette = "Set1") +
  scale_fill_brewer(palette = "Set1") +
  labs(y = "p(GO)", x = "Trial", title = "Trial-by-trial behaviour Sham") +
    scale_x_continuous(breaks = seq(1, 20, by = 1)) +  # Set breaks manually
 # xlim(1, 20) +  # Ensures the plot starts from 1
  theme_bw()

#roll avg per CONDITION
rol_avg_raw <- ggarrange(psham, pai, pdacc,
                    #labels = c("GW", "GAL", "NGW", "NGL"), 
                  ncol = 2, nrow = 2);rol_avg_raw


```




##rolling average per CUE for all three conditions (plot with NGW for three conditions (sham, ai, dACC), plot GW..etc.)

  ***it looks like stimulation to ACC increases the propensity to press in the Go condition. And STIM to both areas slows down learning in the noGO condition***
```{r}
#Grey area is CI

#GW
GW <- subset(tus_filtered, Cue == "GW")

# compute proportion of go responses for each participant
MeanGoResppersub_gw <- GW %>% group_by(ID, req_action, OutValence, TrialCount, condition) %>% summarise(GoResponse = mean(GoResponse))
MeanGoResppersub_gw <- na.omit(MeanGoResppersub_gw)
MeanGoResp_gw <- MeanGoResppersub_gw %>% group_by(req_action, OutValence, TrialCount, condition) %>% summarise(GoResponse = mean(GoResponse))

#plot######################play with lines
GW<-ggplot(data=MeanGoResp_gw, mapping =aes(TrialCount, GoResponse, colour=condition)) + 
  geom_smooth(linetype = "longdash") +
  scale_colour_brewer(palette = "Set1") +
   #facet_grid(~condition)+
   xlim(NA, 20)+
  ylim(0.05, 1)+
  labs(y = "p(GO)", x = "Trial", title = "Trial-by-trial behaviour_GW") +theme_bw() 

#GAL
GAL <- subset(tus_filtered, Cue == "GAL")

# compute proportion of go responses for each participant
MeanGoResppersub_gal <- GAL %>% group_by(ID, TrialCount, condition) %>% summarise(GoResponse = mean(GoResponse))
MeanGoResppersub_gal <- na.omit(MeanGoResppersub_gal)
MeanGoResp_gal <- MeanGoResppersub_gal %>% group_by(TrialCount, condition) %>% summarise(GoResponse = mean(GoResponse))

#plot
GAL<-ggplot(data=MeanGoResp_gal, mapping =aes(TrialCount, GoResponse, colour=condition)) + 
  geom_smooth(linetype = "longdash") +
  scale_colour_brewer(palette = "Set1") +
   #facet_grid(~condition)+
   xlim(NA, 20)+
     ylim(0.05, 1)+
  labs(y = "p(GO)", x = "Trial", title = "Trial-by-trial behaviour_GAL") +theme_bw() 

#NGW
NGW <- subset(tus_filtered, Cue == "NGW")

# compute proportion of go responses for each participant
MeanGoResppersub_NGW <- NGW %>% group_by(ID, TrialCount, condition) %>% summarise(GoResponse = mean(GoResponse))
MeanGoResppersub_NGW <- na.omit(MeanGoResppersub_NGW)
MeanGoResp_NGW <- MeanGoResppersub_NGW %>% group_by(TrialCount, condition) %>% summarise(GoResponse = mean(GoResponse))

#plot - need to work on linetype
NGW<-ggplot(MeanGoResp_NGW) + 
  geom_smooth(aes(TrialCount, GoResponse, colour=condition )) +
  scale_colour_brewer(palette = "Set1") +
  # facet_grid(~condition)+
   xlim(NA, 20)+
     ylim(0.05, 1)+
  labs(y = "p(GO)", x = "Trial", title = "Trial-by-trial behaviour_NGW") +theme_bw() 



#NGW
NGL <- subset(tus_filtered, Cue == "NGL")

# compute proportion of go responses for each participant
MeanGoResppersub_NGL <- NGL %>% group_by(ID, TrialCount, condition) %>% summarise(GoResponse = mean(GoResponse))
MeanGoResppersub_NGL <- na.omit(MeanGoResppersub_NGL)
MeanGoResp_NGL <- MeanGoResppersub_NGL %>% group_by(TrialCount, condition) %>% summarise(GoResponse = mean(GoResponse))

#plot
NGL<-ggplot(MeanGoResp_NGL) + 
  geom_smooth(aes(TrialCount, GoResponse, colour=condition )) +
  scale_colour_brewer(palette = "Set1") +
  # facet_grid(~condition)+
   xlim(NA, 20)+
      ylim(0.05, 0.9)+
  labs(y = "p(GO)", x = "Trial", title = "Trial-by-trial behaviour_NGL") + theme_bw() 


# Determine the maximum and minimum values of GoResponse, cause NGL depricated
max_response <- max(c(MeanGoResp_gw$GoResponse, MeanGoResp_gal$GoResponse, MeanGoResp_NGW$GoResponse, MeanGoResp_NGL$GoResponse))
min_response <- min(c(MeanGoResp_gw$GoResponse, MeanGoResp_gal$GoResponse, MeanGoResp_NGW$GoResponse, MeanGoResp_NGL$GoResponse))

# Set the y-axis limits with a buffer for error bars
y_min <- min_response - 0.1  # Adjust the buffer as needed
y_max <- max_response + 0.0  # Adjust the buffer as needed

# Update the y-axis limits for all plots
GW <- GW + ylim(y_min, y_max)
GAL <- GAL + ylim(y_min, y_max)
NGW <- NGW + ylim(y_min, y_max)
NGL <- NGL + ylim(y_min, y_max)

# Combine the plots
cues <- ggarrange(GW, GAL, NGW, NGL, ncol = 2, nrow = 2)
cues

```



more raw per Cue
```{r}
#Grey area is CI
# Define custom palette for CIs, different for each condition
custom_palette <- c("#FFCCFF", "#CCCCCC", "#66F799")  # Example colors, adjust as needed

#GW
GW <- subset(tus_filtered, Cue == "GW")

# compute proportion of go responses for each participant
# Summarize data to calculate mean and CIs
 mean_GW <- GW %>% 
  group_by(Cue, req_action, OutValence, TrialCount, condition) %>% 
  summarise(GoResponse = mean(GoResponse))

# Summarize data to calculate mean and confidence intervals
meango_GW <- mean_GW %>%
  group_by(TrialCount, OutValence, condition, req_action) %>%
  summarise(
    GoResponse = mean(GoResponse),
    n = n(),
    se = ifelse(n > 1, sd(GoResponse) / sqrt(n), 0.1),  # Adjusted to assume a fixed SE for small groups
    lower_ci = ifelse(n > 1, GoResponse - qt(1 - 0.05 / 2, n - 1) * se, GoResponse - 0.2),
    upper_ci = ifelse(n > 1, GoResponse + qt(1 - 0.05 / 2, n - 1) * se, GoResponse + 0.2)
  ) %>%
  ungroup()

# Plotting
pgw <- ggplot(meango_GW, aes(x = TrialCount, y = GoResponse, colour = condition, group = condition)) + 
  geom_line() +
  geom_point() +
  geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci, fill = condition), alpha = 0.2, colour = NA) +
  scale_colour_brewer(palette = "Set1") +  # Color for lines (if needed)
  scale_fill_manual(values = custom_palette) +  # Custom colors for CI fills
  scale_linetype_manual(values = c("solid", "dashed")) +  # Line types
  labs(y = "p(GO)", x = "Trial", title = "Trial-by-trial behavior GW") +
  scale_x_continuous(breaks = seq(1, 20, by = 1)) +
  theme_bw()



#GAL
GAL <- subset(tus_filtered, Cue == "GAL")

# compute proportion of go responses for each participant
# Summarize data to calculate mean and CIs
 mean_GAL <- GAL %>% 
  group_by(Cue, req_action, OutValence, TrialCount, condition) %>% 
  summarise(GoResponse = mean(GoResponse))

# Summarize data to calculate mean and confidence intervals
meango_GAL<- mean_GAL %>%
  group_by(TrialCount, OutValence, condition, req_action) %>%
  summarise(
    GoResponse = mean(GoResponse),
    n = n(),
    se = ifelse(n > 1, sd(GoResponse) / sqrt(n), 0.1),  # Adjusted to assume a fixed SE for small groups
    lower_ci = ifelse(n > 1, GoResponse - qt(1 - 0.05 / 2, n - 1) * se, GoResponse - 0.2),
    upper_ci = ifelse(n > 1, GoResponse + qt(1 - 0.05 / 2, n - 1) * se, GoResponse + 0.2)
  ) %>%
  ungroup()

# Plotting
pgal <- ggplot(meango_GAL, aes(x = TrialCount, y = GoResponse, colour = condition, group = condition)) + 
  geom_line() +
  geom_point() +
  geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci, fill = condition), alpha = 0.2, colour = NA) +
  scale_colour_brewer(palette = "Set1") +  # Color for lines (if needed)
  scale_fill_manual(values = custom_palette) +  # Custom colors for CI fills
  scale_linetype_manual(values = c("solid", "dashed")) +  # Line types
  labs(y = "p(GO)", x = "Trial", title = "Trial-by-trial behavior GAL") +
  scale_x_continuous(breaks = seq(1, 20, by = 1)) +
  theme_bw()





#NGW
NGW <- subset(tus_filtered, Cue == "NGW")

# compute proportion of go responses for each participant
# Summarize data to calculate mean and CIs
 mean_NGW <- NGW %>% 
  group_by(Cue, req_action, OutValence, TrialCount, condition) %>% 
  summarise(GoResponse = mean(GoResponse))

# Summarize data to calculate mean and confidence intervals
meango_NGW<- mean_NGW %>%
  group_by(TrialCount, OutValence, condition, req_action) %>%
  summarise(
    GoResponse = mean(GoResponse),
    n = n(),
    se = ifelse(n > 1, sd(GoResponse) / sqrt(n), 0.1),  # Adjusted to assume a fixed SE for small groups
    lower_ci = ifelse(n > 1, GoResponse - qt(1 - 0.05 / 2, n - 1) * se, GoResponse - 0.2),
    upper_ci = ifelse(n > 1, GoResponse + qt(1 - 0.05 / 2, n - 1) * se, GoResponse + 0.2)
  ) %>%
  ungroup()

# Plotting
pngw <- ggplot(meango_NGW, aes(x = TrialCount, y = GoResponse, colour = condition, group = condition)) + 
  geom_line() +
  geom_point() +
  geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci, fill = condition), alpha = 0.2, colour = NA) +
  scale_colour_brewer(palette = "Set1") +  # Color for lines (if needed)
  scale_fill_manual(values = custom_palette) +  # Custom colors for CI fills
  scale_linetype_manual(values = c("solid", "dashed")) +  # Line types
  labs(y = "p(GO)", x = "Trial", title = "Trial-by-trial behavior NGW") +
  scale_x_continuous(breaks = seq(1, 20, by = 1)) +
  theme_bw()




#NGL
NGL <- subset(tus_filtered, Cue == "NGL")

# compute proportion of go responses for each participant
# Summarize data to calculate mean and CIs
 mean_NGL <- NGL %>% 
  group_by(Cue, req_action, OutValence, TrialCount, condition) %>% 
  summarise(GoResponse = mean(GoResponse))

# Summarize data to calculate mean and confidence intervals
meango_NGL<- mean_NGL %>%
  group_by(TrialCount, OutValence, condition, req_action) %>%
  summarise(
    GoResponse = mean(GoResponse),
    n = n(),
    se = ifelse(n > 1, sd(GoResponse) / sqrt(n), 0.1),  # Adjusted to assume a fixed SE for small groups
    lower_ci = ifelse(n > 1, GoResponse - qt(1 - 0.05 / 2, n - 1) * se, GoResponse - 0.2),
    upper_ci = ifelse(n > 1, GoResponse + qt(1 - 0.05 / 2, n - 1) * se, GoResponse + 0.2)
  ) %>%
  ungroup()
  
  # Plotting
pngl <- ggplot(meango_NGL, aes(x = TrialCount, y = GoResponse, colour = condition, group = condition)) + 
  geom_line() +
  geom_point() +
  geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci, fill = condition), alpha = 0.2, colour = NA) +
  scale_colour_brewer(palette = "Set1") +  # Color for lines (if needed)
  scale_fill_manual(values = custom_palette) +  # Custom colors for CI fills
  scale_linetype_manual(values = c("solid", "dashed")) +  # Line types
  labs(y = "p(GO)", x = "Trial", title = "Trial-by-trial behavior NGL") +
  scale_x_continuous(breaks = seq(1, 20, by = 1)) +
  theme_bw()


# Combine the plots
cues_r <- ggarrange(pgw, pgal, pngw, pngl, ncol = 2, nrow = 2)
cues_r

```


## Probability of correct per participant ***IS THAT CORRECT?***
```{r}
tus_correct<-tus_filtered %>%  group_by(ID, Valence=OutValence,condition, Action=req_action) %>% summarise(correct = mean(correct))
#tus_correct_sub_gen <- tus_correct %>% group_by(OutValence, req_action, condition) %>% summarise(correct = mean(correct))
tus_correct<-na.omit(tus_correct)
# Identify outliers
outliers <- boxplot.stats(tus_correct$correct)$out
# Remove outliers from the dataset
tus_correct <- tus_correct[!tus_correct$correct %in% outliers, ]
# Plot without outliers
yarrr::pirateplot(formula = correct ~ condition + Action + Valence,    
                  data = tus_correct,           
                  theme = 2,
                  # main = "Proba_correct/condition",
                  ylab = "(p) of correct",
                  ylim = c(0.4, 1),
                  bean.f.o = .4, # Bean fill
                  bean.b.o = .2, # Light bean border
                  point.o = .5, # Points (opacity)
                  inf.disp = "line",
                  inf.f.o = 0.8, # Inference fill
                  inf.b.o = 0.8, # Inference border
                  avg.line.o = 0, # Average line
                  point.pch = 21,
                  point.bg = "white",
                  point.cex = .7)


##maybe this to be the same as the RTs
yarrr::pirateplot(formula = correct ~  Action + Valence + condition,    
                  data = tus_correct,           
                  theme = 2,
                 # main = "Condition",
                  ylab = "(p) of correct",
                  ylim = c(0.4,1),
                  bean.f.o = .4, # Bean fill
                  bean.b.o = .2, # Light bean border
                  point.o = .5, # Points (opacity)
                  inf.disp = "line",
                  inf.f.o = 0.8, # Inference fill
                  inf.b.o = 0.8, # Inference border
                  avg.line.o = 0, # Average line
                  point.pch = 21,
                  point.bg = "white",
                  point.cex = .7)  + facet_grid(~condition) 



# Calculate mean and standard error per condition and req_action
summary_data <- tus_correct %>%
  group_by(Action, condition, Valence) %>%
  summarise(mean_correct = mean(correct),
            se_correct = sd(correct, na.rm = TRUE) / sqrt(n()))

# Plot with error bars 
ggplot(summary_data, aes(x = Action, y = mean_correct, fill = Valence)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.75), width = 0.7) +  # Increase width for thicker bars
  geom_errorbar(aes(ymin = mean_correct - se_correct, ymax = mean_correct + se_correct),
                position = position_dodge(width = 0.75), width = 0.25) +  # Adjust width for error bars
  facet_wrap(~ condition) +
  labs(title = "Mean Correct") +
  theme_bw() +
  coord_cartesian(ylim = c(0.50, 0.95)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for better readability



# Boxplot without individual data points
ggplot(tus_correct, aes(x = Action, y = correct, fill = Valence)) +
  geom_boxplot(position = position_dodge(width = 0.75), outlier.shape = NA) +  # Use outlier.shape = NA to hide outliers
  facet_wrap(~ condition) +
  geom_jitter(position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.65), alpha = 0.2) +  # Add jittered points
  labs(title = "Distribution of Correct Responses") +
  theme_bw() +
  coord_cartesian(ylim = c(0.45, 1.05)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for better readability


```


# ACCURACY PLOTS 
### proportion of correct per participant per condition ***IMPORTANT FOR THE GW FOR THE AI***

```{r}
# 1. Rename the column in your dataframe
tus_correct_meaned <- rename(tus_filtered, valence = OutValence)

# Plot with adjusted y-axis and x-axis limits
pirateplot(formula = correct ~ condition + valence + req_action,
           data = tus_correct_meaned,
           theme = 0,
           bean.f.o = .6, # Bean fill
           point.o = .3, # Points
           inf.f.o = .7, # Inference fill
           inf.b.o = .8, # Inference border
           avg.line.o = 1, # Average line
           bar.f.o = .5, # Bar
           inf.f.col = "white", # Inf fill col
           inf.b.col = "black", # Inf border col
           avg.line.col = "black", # avg line col
           point.pch = 21,
           point.bg = "white",
           point.col = "black",
           point.cex = .7,
           ylim = c(0.4, 0.97))



# 2.a as above. Calculate summary statistics (mean and standard deviation)

ppts<-tus_filtered %>% group_by(ID) %>%
   distinct(ID) %>% 
  nrow() # number of participants

MeanGoResppersub_cond <- tus_filtered %>% group_by(ID, Cue, req_action, OutValence, block, TrialCount, condition, correct) %>% summarise(GoResponse = mean(GoResponse))
MeanGoResppersub_cond <- na.omit(MeanGoResppersub_cond)
#MeanGoResppersub_cond <- MeanGoResppersub_cond %>% group_by(Cue, req_action, block, OutValence, TrialCount) %>% summarise(GoResponse = mean(GoResponse))

summary_data <- MeanGoResppersub_cond %>%
  group_by(condition, req_action, OutValence) %>%
  summarise(
    mean_correct = mean(correct),
    sd_correct = sd(correct),
    count = n(),
    se_correct =sd_correct/sqrt(ppts),
  ) %>%
  na.omit()
# Create a ggplot with error bars, bars, and facets <- i think pirate plot in line 541 better!!!!!
ggplot(summary_data, aes(x = condition, y = mean_correct, ymin = mean_correct - se_correct, ymax = mean_correct + se_correct, fill = condition)) +
  geom_errorbar(position = position_dodge(width = 0.75), width = 0.2) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.75), width = 0.5, alpha = 0.5) +
  geom_text(aes(label = round(mean_correct, 2)), vjust = -3, position = position_dodge(width = 0.75)) +
    coord_cartesian(ylim = c(0.4, 1.1)) +
  facet_grid(req_action ~ OutValence) 




# 2.b add points to the above 

# Merge summary_data and tus data
merged_data <- merge(tus_filtered, summary_data, by = "condition", all.x = TRUE) #merging should be a left join. In a left join, all rows from the left data frame (tus in this case) will be retained, and matching rows from the right data frame (summary_data) will be added. If there are no matches, the columns from the right data frame will contain missing values (NA).
merged_data <- merged_data %>% na.omit()


# Calculate the minimum and maximum y-values in your data
            #y_min <- min(summary_data$mean_correct - summary_data$se_correct)
            #y_max <- max(summary_data$mean_correct + summary_data$se_correct)

# Create a ggplot with error bars, bars, data points, and facets
ggplot(data = summary_data, aes(x = condition, y = mean_correct, fill = condition)) +
  geom_errorbar(aes(ymin = mean_correct - se_correct, ymax = mean_correct + se_correct),
                position = position_dodge(width = 0.75), width = 0.2) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.75), width = 0.5, alpha = 0.5) +

  # Use merged_data for geom_point instead of tus
  geom_point(data = merged_data, aes(x = condition, y = mean_correct, color = condition),
             position = position_dodge(width = 0.75), size = 1)+
  geom_text(aes(label = round(mean_correct, 3)), vjust = -3, position = position_dodge(width = 0.75)) +
  facet_grid(req_action ~ OutValence) +
  # Set y-axis limits dynamically based on data
                #ylim(y_min, y_max)
  coord_cartesian(ylim=c(0.4,1))



#not sure, because it shows that NGW for AI is lower when i am excluding above 0.5 accuracy
# 3. YET ANOTHET PIRATE PLOT,  (named: Acc_perall5)
# Filter the data to exclude values outside the desired y-axis range
tus_filt <- tus_correct %>% filter(correct >= 0.43 & correct <= 1)

#pirate plot
pirateplot(formula = correct ~ condition  + Action +Valence,
           data = tus_filt,
                           theme = 0,
           #main = "Fully customized pirateplot",
           #pal = "southpark", # southpark color palette
           bean.f.o = .6, # Bean fill
           point.o = .3, # Points
           inf.f.o = .7, # Inference fill
           inf.b.o = .8, # Inference border
           avg.line.o = 1, # Average line
           bar.f.o = .5, # Bar
           inf.f.col = "white", # Inf fill col
           inf.b.col = "black", # Inf border col
           avg.line.col = "black", # avg line col
           #bar.f.col = gray(.8), # bar filling color
           point.pch = 21,
           point.bg = "white",
           point.col = "black",
           point.cex = .7)+
          coord_cartesian(ylim=c(0.5,1))




#boxplot

# Create the boxplot with facets by Action and Valence
ggplot(tus_filt, aes(x = condition, y = correct, fill = condition)) +
  geom_boxplot(position = position_dodge(width = 0.75), outlier.shape = NA) +  # Use outlier.shape = NA to hide outliers
  geom_jitter(position = position_jitterdodge(jitter.width = 0.1, dodge.width = 0.75), alpha = 0.3) +  # Add jittered points
  facet_grid(Action ~ Valence) +  # Facet by Action and Valence
  labs(title = "Distribution of Correct Responses by Condition, Action, and Valence",
       x = "Condition",
       y = "Correct Responses") +
  theme_bw() +
  coord_cartesian(ylim = c(0.5, 1)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for better readability


```



            
## How about RTs? 

      #this might contain wrongdata sets
```{r}

# 1. Calculate summary statistics (mean and standard deviation)     --> mean RT of all, 
######NB do it per participant - the dots not all RTs in the plot)
      #filter data to exclude very high values
# Filter data
filtered_data_rt <- tus_filtered %>% filter(RT >= 600, RT <= 800)

# Calculate mean reaction time per participant
mean_rt <- filtered_data_rt %>%
  group_by(ID, condition, req_action, OutValence) %>%
  summarise(mean_RT = mean(RT, na.rm = TRUE))

# Create pirateplot
pirateplot(formula = mean_RT ~ condition + req_action + OutValence,
           data = mean_rt,
           theme = 0,
           bean.f.o = 0.2, # Bean fill
           point.o = 0.3, # Points
           inf.f.o = 0.7, # Inference fill
           inf.b.o = 0.8, # Inference border
           avg.line.o = 1, # Average line
           bar.f.o = 0.5, # Bar
           inf.f.col = "white", # Inf fill col
           inf.b.col = "black", # Inf border col
           avg.line.col = "black", # avg line col
           point.pch = 21,
           point.bg = "white",
           point.col = "black",
           point.cex = 0.7)


#1.a boxplot
# Create the boxplot with facets by req_action and OutValence
ggplot(mean_rt, aes(x = condition, y = mean_RT, fill = condition)) +
    geom_boxplot(position = position_dodge(width = 0.75), outlier.shape = NA) +  # Use outlier.shape = NA to hide outliers
    geom_jitter(position = position_jitterdodge(jitter.width = 0.1, dodge.width = 0.75), alpha = 0.3) +  # Add jittered points
    facet_grid(req_action ~ OutValence) +  # Facet by req_action and OutValence
    labs(title = "Mean Reaction Time by Condition, Action, and Valence",
         x = "Condition",
         y = "Mean Reaction Time (ms)") +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for better readability



# 2. better compute mean_rt for each participant -that should be the correct - good but no error bars
Meanrtpersub_rt <- tus_filtered %>% group_by(req_action, OutValence, condition, response, RT) %>% summarise(mean_rt = mean(RT))
Meanrtpersub_rt <- na.omit(Meanrtpersub_rt)
#Meanrt_rt <- Meanrtpersub_rt %>% group_by(req_action, OutValence, condition) %>% summarise(mean_rt = mean(mean_rt_per_Subject))
Meanrtpersub_rt <- Meanrtpersub_rt %>% filter(RT >= 300, RT <= 800)%>% filter(response != "no_press")

pirateplot(formula =  mean_rt ~ condition + OutValence + req_action,
           data = Meanrtpersub_rt,
                           theme = 0,
           #main = "mean_RT_per_SUB",
           #pal = "southpark", # southpark color palette
           bean.f.o = .2, # Bean fill
           point.o = .3, # Points
           inf.f.o = .7, # Inference fill
           inf.b.o = .8, # Inference border
           avg.line.o = 1, # Average line
           bar.f.o = .5, # Bar
           inf.f.col = "white", # Inf fill col
           inf.b.col = "black", # Inf border col
           avg.line.col = "black", # avg line col
           #bar.f.col = gray(.8), # bar filling color
           point.pch = 21,
           point.bg = "white",
           point.col = "black",
           point.cex = .7)



#  3. AND with full tus !!TO CHECK WHEN I ADD TRIAL COUNT AND BLOCK CHANGES LOADS. ask NADEIGE :-)
Meanrtpersub_rt2 <- tus_filtered %>% group_by(ID, Cue, req_action, OutValence,  condition, RT) %>% summarise(mean_rt = mean(RT))
Meanrtpersub_rt2 <- na.omit(Meanrtpersub_rt2) # group by extra :block, TrialCount,


summary_data_rt <- Meanrtpersub_rt2 %>%
  group_by(condition, req_action, OutValence) %>%
  summarise(
    mean_rt = mean(RT),
    sd_rt = sd(RT),  # Calculate the standard deviation of RT
    count = n(),
    se_rt = sd_rt / sqrt(ppts)  # Calculate the standard error
  ) %>%
  na.omit()
# Create a ggplot with error bars, bars, and facets - pirate plot in the beginning is better (for RTs) - line 286
ggplot(summary_data_rt, aes(x = condition, y = mean_rt, ymin = mean_rt - se_rt, ymax = mean_rt + se_rt, fill = condition)) +
  geom_errorbar(position = position_dodge(width = 0.75), width = 0.2) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.75), width = 0.5, alpha = 0.5) +
  geom_text(aes(label = round(mean_rt, 2)), vjust = -2, position = position_dodge(width = 0.75)) + #means shown
  ylim(0,800)+
 facet_grid(req_action ~ OutValence)


 # 4. as above - adding data points
        #Merge summary_data and tus data 
merged_data_rt <- merge(tus, summary_data_rt, by = "condition", all.x = TRUE) 
              #merged_data_rt <- merged_data_rt %>% na.omit()

# Create a ggplot with error bars, bars, data points, and facets
g_plot<-ggplot(data = summary_data_rt, aes(x = condition, y = mean_rt, fill = condition)) +
  geom_errorbar(aes(ymin = mean_rt - se_rt, ymax = mean_rt + se_rt),
                position = position_dodge(width = 0.75), width = 0.2) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.75), width = 0.5, alpha = 0.5) +
# Use merged_data for geom_point instead of tus
  geom_point(data = merged_data_rt, aes(x = condition, y = mean_rt, color = condition),
             position = position_dodge(width = 0.75), size = 2, alpha = 0.5) +
  geom_text(aes(label = round(mean_rt, 3)), vjust = -2, position = position_dodge(width = 0.75)) +
  ylim(0,900)+
  facet_grid(req_action ~ OutValence) ;g_plot
```


## performance per participant
```{r}
#summary - correct Cues
ggplot(tus_filtered,
       aes(x=Cue, y= correct, color = Cue, fill= Cue)) + 
  geom_bar(stat = "identity")

#correct counts per Cue
ccc<-tus_filtered %>% group_by (Cue)%>% count (correct);View (ccc)

#correct counts per Cue per ID
ccc_id<-tus_filtered %>% group_by (Cue, ID)%>% count (correct);View (ccc_id)

#correct per ID
c<-tus_filtered %>% filter(correct == "1")%>% group_by (ID)%>% count (correct);c

#response per ID
response_per_ppt <-tus_filtered %>% group_by (ID)%>% count (response);View (response_per_ppt)

mean(c$n) #avg of 294 correct responses--> 
          #may be if a person has less than 230 or 210? correct responses --> CUT? or below 53? see below aggregate
```


   
   
#RT trial-by_trial behaviour 

NEED TO EXCLUDE THE NO_PRESSES AS RT = 0.0001 AND LOWERS THE RESPONSES DOWN (FASTER)
```{r}
#trial_by_trial behaviour RT 

#for all

# compute proportion of go responses for each participant (first sum per ID, then feed that into general summary)
MeanRTpersub <- tus_filtered %>%
  filter(response != "no_press") %>%
  group_by(ID, Cue, req_action, OutValence, block, TrialCount, response) %>%
  summarise(meanRT = mean(RT))

MeanRT <- MeanRTpersub %>% group_by(Cue, req_action, OutValence, block,  TrialCount) %>% summarise(meanRT = mean(meanRT))

#plot of RT responses over time 
ggplot(MeanRT) + 
  geom_smooth(aes(TrialCount, meanRT,colour=OutValence, lty = req_action)) +
  scale_colour_brewer(palette = "Set1") +
  labs(y = "RT", x = "Trial", title = "Trial-by-trial behaviour_RT") +
  xlim (0,20) +theme_bw() 
#plot of RT per block
ggplot(MeanRT) + 
  geom_smooth(aes(TrialCount,meanRT,colour=OutValence, lty = req_action)) +
  scale_colour_brewer(palette = "Set1") +
  facet_grid(~block)+
  theme_bw() +
  labs(y = "RT", x = "Trial", title = "Trial-by-trial behaviour_RT_perBlock") +
  xlim(0, 20) +
  ylim(500, 1100)
```


#RT trial-by_trial behaviour by condition
```{r}

#AI - 
ai <- subset(tus_filtered, condition == "c.ai")

MeanRTpesppersub_ai <- ai %>%
  filter(response != "no_press") %>% group_by(ID, Cue, req_action, OutValence, TrialCount, response) %>% summarise(meanRT = mean(RT))

MeanRTResp.ai <- MeanRTpesppersub_ai %>% group_by(Cue, req_action, OutValence, TrialCount) %>% summarise(meanRT = mean(meanRT))

#plot
ai_avg<- ggplot(MeanRTResp.ai) + 
  geom_smooth(aes(TrialCount, meanRT,colour=OutValence, lty = req_action)) +
  scale_colour_brewer(palette = "Set1") +
    #facet_grid(~block)+
  labs(y = "RT", x = "Trial", title = "Trial-by-trial behaviour for AI_RT") +
   xlim(1, 20)+
 theme_bw() +
  ylim(500, 1100)


    #dACC - 
dacc <- subset(tus_filtered, condition == "b.dacc")
#dacc <- na.omit(dacc)

# compute proportion of go responses for each participant
MeanRTpesppersub_dacc <- dacc %>% filter(response != "no_press") %>% group_by(ID, Cue, req_action, OutValence, TrialCount, response)  %>% summarise(meanRT = mean(RT))
MeanRTpersp.dacc <- MeanRTpesppersub_dacc %>% group_by(Cue, req_action, OutValence, TrialCount ) %>% summarise(meanRT = mean(meanRT))

#plot
dacc_avg<- ggplot(MeanRTpersp.dacc) + 
  geom_smooth(aes(TrialCount, meanRT,colour=OutValence, lty = req_action)) +
  scale_colour_brewer(palette = "Set1") +
    #  facet_grid(~block)+
  labs(y = "RT", x = "Trial", title = "Trial-by-trial behaviour for dACC_RT")+
   xlim(1, 20)+ theme_bw()  +
  ylim(500, 1100)



    #Sham
sham <- subset(tus_filtered, condition == "a.sham")

# compute proportion of go responses for each participant
MeanRTpersub_sham <- sham %>%  filter(response != "no_press") %>% group_by(ID, Cue, req_action, OutValence, TrialCount, response) %>% summarise(meanRT = mean(RT))

MeanRTResp.sham <- MeanRTpersub_sham %>% group_by(Cue, req_action, OutValence, TrialCount) %>% summarise(meanRT = mean(meanRT))

#plot
sham_avg<- ggplot(MeanRTResp.sham) + 
  geom_smooth(aes(TrialCount, meanRT,colour=OutValence, lty = req_action)) +
  scale_colour_brewer(palette = "Set1") +
     # facet_grid(~block)+
  labs(y = "RT", x = "Trial", title = "Trial-by-trial behaviour for sham_RT") +
   xlim(1, 20)+
 theme_bw()  +
  ylim(500, 1100)

#roll avg per CONDITION
avg_rt <- ggarrange(sham_avg, ai_avg, dacc_avg,
                    #labels = c("GW", "GAL", "NGW", "NGL"), 
                  ncol = 2, nrow = 2);avg_rt
```


Trial by trial per condition - without smooth 
```{r}

# Define a function to calculate mean RT and create the RT plot for each condition
plot_RT <- function(data, condition_name) {
    meanRT_data <- data %>%
        filter(response != "no_press") %>%
        group_by(Cue, req_action, OutValence, TrialCount) %>%
        summarise(meanRT = mean(RT))
    
    p <- ggplot(meanRT_data, aes(x = TrialCount, y = meanRT, colour = OutValence, linetype = req_action)) +
        geom_line(aes(group = interaction(OutValence, req_action))) +
        geom_point() +
        scale_colour_brewer(palette = "Set1") +
        labs(y = "RT", x = "Trial", title = paste("Trial-by-trial behavior for", condition_name, "_RT")) +
        xlim(1, 20) +
        ylim(400, 950) +
        theme_bw()
    
    return(p)
}

# Example usage for each condition
ai <- subset(tus_filtered, condition == "c.ai")
dacc <- subset(tus_filtered, condition == "b.dacc")
sham <- subset(tus_filtered, condition == "a.sham")

# Create RT plots for each condition
p_ai_RT <- plot_RT(ai, "AI")
p_dacc_RT <- plot_RT(dacc, "dACC")
p_sham_RT <- plot_RT(sham, "Sham")

# Arrange plots into a grid: all plots of equal size, no labels for AI and Sham
avg_plots <- ggarrange(p_sham_RT, p_ai_RT, p_dacc_RT,
                       labels = c("", "", ""),
                       ncol = 1, heights = rep(1, 3))  # Equal heights for all plots

# Display the grid of plots
avg_plots
```

   
   
   
   ## RTrolling average per CUE for all three conditions (plot with NGW for three conditions (sham, ai, dACC), plot GW..etc.)

```{r}
#Grey area is CI

#GW
GW <- subset(tus_filtered, Cue == "GW")

# compute proportion of go responses for each participant
MeanRTpersub_gw <- GW %>%   filter(response != "no_press") %>%group_by(ID, req_action, OutValence, TrialCount, condition, response) %>% summarise(meanRT = mean(RT))
MeanRTpersub_gw <- na.omit(MeanRTpersub_gw)
MeanRTResp_gw <- MeanRTpersub_gw %>% group_by(req_action, OutValence, TrialCount, condition) %>% summarise(meanRT = mean(meanRT))

#plot######################play with lines
GW_rt<-ggplot(data=MeanRTResp_gw, mapping =aes(TrialCount, meanRT, colour=condition)) + 
  geom_smooth(linetype = "longdash", alpha = 0.3) +
  scale_colour_brewer(palette = "Set1") +
   #facet_grid(~condition)+
   xlim(1, 20)+
  ylim(NA, 900)+
  labs(y = "RT", x = "Trial", title = "Trial-by-trial behaviour_GW_RT") +theme_bw() 

#GAL
GAL <- subset(tus_filtered, Cue == "GAL")

# compute proportion of go responses for each participant
MeanRTpersub_gal <- GAL %>%  filter(response != "no_press") %>%group_by(ID, TrialCount, condition) %>% summarise(meanRT = mean(RT))
MeanRTpersub_gal <- na.omit(MeanRTpersub_gal)
MeanRTResp_gal <- MeanRTpersub_gal %>% group_by(TrialCount, condition) %>% summarise(meanRT = mean(meanRT))

#plot
GAL_rt<-ggplot(data=MeanRTResp_gal, mapping =aes(TrialCount, meanRT, colour=condition)) + 
  geom_smooth(linetype = "longdash", alpha = 0.3) +
  scale_colour_brewer(palette = "Set1") +
   #facet_grid(~condition)+
   xlim(NA, 20)+
     ylim(400, 900)+
  labs(y = "RT", x = "Trial", title = "Trial-by-trial behaviour_GAL_RT") +theme_bw() 

#NGW
NGW <- subset(tus_filtered, Cue == "NGW")

# compute proportion of go responses for each participant
MeanRTpersub_NGW <- NGW %>% filter(response != "no_press") %>%group_by(ID, TrialCount, condition, response) %>% summarise(meanRT = mean(RT))
MeanRTpersub_NGW <- na.omit(MeanRTpersub_NGW)
MeanRTResp_NGW <- MeanRTpersub_NGW %>% group_by(TrialCount, condition) %>% summarise(meanRT = mean(meanRT))

#plot - need to work on linetype
NGW_rt<-ggplot(MeanRTResp_NGW) + 
  geom_smooth(aes(TrialCount, meanRT, colour=condition), size = 1)  +
  scale_colour_brewer(palette = "Set1") +
  # facet_grid(~condition)+
   xlim(NA, 20)+
     ylim(400,900)+
  labs(y = "RT", x = "Trial", title = "Trial-by-trial behaviour_NGW_RT") +theme_bw() 



#NGL
NGL <- subset(tus_filtered, Cue == "NGL")

# compute proportion of go responses for each participant
MeanRTpersub_NGL <- NGL %>% filter(response != "no_press") %>%group_by(ID, TrialCount, condition, response) %>% summarise(meanRT = mean(RT))
MeanRTpersub_NGL <- na.omit(MeanRTpersub_NGL)
MeanRTResp_NGL <- MeanRTpersub_NGL %>% group_by(TrialCount, condition) %>% summarise(meanRT = mean(meanRT))

#plot
NGL_rt<-ggplot(MeanRTResp_NGL) + 
  geom_smooth(aes(TrialCount, meanRT, colour=condition ), size = 1)  +
  scale_colour_brewer(palette = "Set1") +
  # facet_grid(~condition)+
   xlim(NA, 20)+
      coord_cartesian(ylim = c(400, 900))+
  labs(y = "RT", x = "Trial", title = "Trial-by-trial behaviour_NGL_RT") + theme_bw() 



#CUES PER CONDITION RT
cues_rt <- ggarrange(GW_rt, GAL_rt, NGW_rt, NGL_rt,
                    #labels = c("GW", "GAL", "NGW", "NGL"), 
                  ncol = 2, nrow = 2);cues_rt
   #ylim(0.05, 0.9); 
```

   
   #Trial by Trial per Cue and condition without geom_smooth
```{r}
# Example custom palette for conditions, adjust as needed
#custom_palette <- c("#FFCCFF", "#CCCCCC", "#66F799")  # Example colors, adjust as needed

# Function to create RT plot with lines connecting points for conditions
plot_RT <- function(tus_filtered, Cue) {
  meanRT_data <- tus_filtered %>%
    filter(response != "no_press") %>%
    group_by(TrialCount, condition) %>%
    summarise(
      meanRT = mean(RT),
      sdRT = sd(RT),
      seRT = sd(RT) / sqrt(n()),
      lower_ci = meanRT - qt(1 - 0.05 / 2, n() - 1) * seRT,
      upper_ci = meanRT + qt(1 - 0.05 / 2, n() - 1) * seRT
    )
  
  p <- ggplot(meanRT_data, aes(x = as.factor(TrialCount), y = meanRT, colour = condition, group = condition)) +
    geom_line() +
    geom_point() +
  #  geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci, fill = condition), alpha = 0.2, colour = NA) +  # Add shaded CI
  #  scale_colour_manual(values = custom_palette) +  # Custom colors for conditions
    labs(y = "RT", x = "Trial", title = paste("Trial-by-trial behavior", Cue)) +
    theme_bw()
  
  return(p)
}

# Example: Subset data for each cue and condition
GW <- subset(tus_filtered, Cue == "GW")
GAL <- subset(tus_filtered, Cue == "GAL")
NGW <- subset(tus_filtered, Cue == "NGW")
NGL <- subset(tus_filtered, Cue == "NGL")

# Create RT plots for each cue
pgw <- plot_RT(GW, "GW")
pgal <- plot_RT(GAL, "GAL")
pngw <- plot_RT(NGW, "NGW")
pngl <- plot_RT(NGL, "NGL")

# Arrange plots into a grid
cues_rt <- ggarrange(pgw, pgal, pngw, pngl, ncol = 2, nrow = 2)

# Display the grid of plots
cues_rt


```
   
   
   
   
   

## PROPORTIONs - correct PER PARTCIPANT
```{r}
#the proportion of 1s by participant, + more i.e. sound, and language.
#Because the proportion of 1s in a vector with only 0s and 1s is just the mean, this should work:

df <- aggregate(data=tus_filtered_ex, correct ~ ID +condition, FUN="mean")#fun = mean #https://r-coder.com/aggregate-r/
p <- ggplot(df)
p <- p + geom_bar(mapping=aes(x=correct, y=ID), stat='identity')+
  geom_vline(xintercept = 0.53, col = "red")+ 
  geom_vline(xintercept = 0.50, col = "grey")+
   geom_vline(xintercept = 0.80, col = "green")+
  geom_text(aes(x=0.54, label="53%", y=4), colour="black", angle=90) +
geom_text(aes(x=0.49, label="50%", y=9), colour="black", angle=90)+
  geom_text(aes(x=0.79, label="80%", y=6), colour="black", angle=90)+
  facet_wrap(~condition)
p + ylab('ID')

#same as above but with stat_summary
ggplot(tus_filtered) + 
  stat_summary(aes(x = ID, y = correct), 
               geom = "bar")

#performance per participant and condition
aggregate(data=tus_filtered, correct ~ ID+condition, FUN="mean") #fun = mean #https://r-coder.com/aggregate-r/

df_c <- aggregate(data=tus_filtered, correct ~ ID +condition, FUN="mean")
 
ggplot(data = df_c) + 
  geom_bar(mapping = aes(fill = condition, x = ID, y = correct), stat = "identity", position = "dodge")

#same but with lines and dots
 df_c %>%ggplot(aes(condition, correct, color=ID)) +
   #geom_boxplot()+
  geom_point(aes(fill=ID),size=5) +
 # scale_x_log10()+
  geom_line(aes(group = ID),color="grey")
#ggsave("#performance per participant and condition.png")




#lines and dots per participant and valence/condition - not much sense
df_rt_id <- tus_filtered %>%
  group_by(ID, condition, req_action, OutValence) %>%
  summarise(mean_acc = mean(correct))

ggplot(df_rt_id, aes(x = condition, y = mean_acc, color = ID, group = ID)) +
  geom_point(aes(fill = ID), size = 5) +
  geom_line(color = "grey") +
  facet_grid(req_action ~ OutValence) +
  theme_minimal()

```
 
 
 Accuracy connected with dots per ID -- I need to translate it to bar plots with dots connected 
```{r}


# Summarize the data with mean accuracy
df_acc_id <- tus_filtered %>%
  group_by(ID, condition, req_action, OutValence) %>%
  summarise(mean_acc = mean(correct, na.rm = TRUE)) %>%
  ungroup()

# Function to create individual plots for each condition
plot_condition <- function(condition_name) {
  df_condition <- df_acc_id %>% filter(condition == !!condition_name)
  
  # Check if df_condition is not empty
  if(nrow(df_condition) == 0) {
    return(ggplot() + 
             labs(title = condition_name, x = "Required Action", y = "Mean Accuracy") +
             theme_minimal() + 
             annotate("text", x = 1, y = 1, label = "No data available") +
             theme(legend.position = "none"))
  }
  
  ggplot(df_condition, aes(x = req_action, y = mean_acc, color = ID, group = ID)) +
    geom_point(size = 3) +
    geom_line(size = 0.5) +
    facet_wrap(~ OutValence) +
    theme_minimal() +
    ylim(-0.3, 1.2) +  # Set the y-axis limit to start from 0
    labs(title = condition_name, x = "Required Action", y = "Mean Accuracy") +
    theme(legend.position = "none")
}

# Get unique conditions
conditions <- unique(df_rt_id$condition)

# Create plots for each condition
plots <- lapply(conditions, plot_condition)

# Combine the plots into one image
combined_plot <- wrap_plots(plots) + plot_layout(ncol = 1)

# Display the combined plot
print(combined_plot)




```
 
 
 ## RTs for participants 
```{r}

#the proportion of 1s by participant, + more i.e. sound, and language.
#Because the proportion of 1s in a vector with only 0s and 1s is just the mean, this should work:

df <- aggregate(data = tus_filtered %>% filter(response != "no_press"), RT ~ ID+ condition, FUN = mean)
p <- ggplot(df)
p <- p + geom_bar(mapping=aes(x=RT, y=ID), stat='identity')+
  geom_vline(xintercept = 150, col = "red")+ 
  geom_vline(xintercept = 300, col = "grey")+
   geom_vline(xintercept = 550, col = "green")+
  geom_text(aes(x=150, label="150", y=12), colour="black", angle=90) +
geom_text(aes(x=300, label="300", y=9), colour="black", angle=90)+
  geom_text(aes(x=550, label="550", y=6), colour="black", angle=90) +
  facet_wrap(~condition)
p + ylab('ID')


#rt per participant per condition
aggregate(data=tus_filtered%>% filter(response != "no_press"), RT ~ ID+condition, FUN="mean") #fun = mean #https://r-coder.com/aggregate-r/

df_rt <- aggregate(data=tus_filtered%>% filter(response != "no_press"),RT ~ ID +condition, FUN="mean")
 
ggplot(data = df_rt) + 
  geom_bar(mapping = aes(fill = condition, x = ID, y = RT), stat = "identity", position = "dodge") 
  

#same but with lines and dots
  df_rt %>%ggplot(aes(condition, RT, color=ID)) +#geom_boxplot()+
  geom_point(aes(fill=ID),size=5) +#scale_x_log10()+
  geom_line(aes(group = ID),color="grey")
  
#lines and dots per participant and valence/condition
df_rt <- tus_filtered %>%
  filter(response != "no_press") %>%
  group_by(ID, condition, req_action, OutValence) %>%
  summarise(mean_RT = mean(RT))

ggplot(df_rt, aes(x = condition, y = mean_RT, color = ID, group = ID)) +
  geom_point(aes(fill = ID), size = 5) +
  geom_line(color = "grey") +
  facet_grid(req_action ~ OutValence) +
  theme_minimal()

```

 
 RTs connected with dots per ID
```{r}

# Summarize the data with mean reaction time
df_rt <- tus_filtered %>%
  group_by(ID, condition, req_action, OutValence) %>%
  summarise(mean_rt = mean(RT, na.rm = TRUE)) %>%
  ungroup()

# Function to create individual plots for each condition
plot_condition <- function(condition_name) {
  rt_condition <- df_rt %>% filter(condition == !!condition_name)
  
  # Check if rt_condition is not empty
  if(nrow(rt_condition) == 0) {
    return(ggplot() + 
             labs(title = condition_name, x = "Required Action", y = "Mean Reaction Time") +
             theme_minimal() + 
             annotate("text", x = 1, y = 1, label = "No data available") +
             theme(legend.position = "none"))
  }
  
  ggplot(rt_condition, aes(x = req_action, y = mean_rt, color = ID, group = ID)) +
    geom_point(size = 3) +
    geom_line(size = 0.5) +
    facet_wrap(~ OutValence) +
    theme_minimal() +
    ylim(0, 1000) +  # Set the y-axis limit to start from 0 to 1500
    labs(title = condition_name, x = "Required Action", y = "Mean Reaction Time (ms)") +
    theme(legend.position = "none")
}

# Get unique conditions
conditions <- unique(df_rt$condition)

# Create plots for each condition
plots <- lapply(conditions, plot_condition)

# Combine the plots into one image
combined_rt <- wrap_plots(plots) + plot_layout(ncol = 1)

# Display the combined plot
print(combined_rt)


```
 

##FOLLOW UP BEHAVIOUR - AFTER GENERAL FEEDBACK (all feedback - feedback column)
```{r}

# Filter data for rows where feedback is "win", "lose", or "neutral" and select relevant columns
feed <- subset(tus_filtered, feedback %in% c("win", "lose", "neutral"), select = c("feedback", "followup_beha", "condition"))

# Exclude NA values
feed <- na.omit(feed)

# Calculate counts of 'press' and 'no_press' for each combination of feedback, followup_beha, and condition
feed_data <- feed %>%
  group_by(feedback, followup_beha, condition) %>%
  summarise(count = n()) %>%
  ungroup()

# Calculate the total counts (sum of 'press' and 'no_press') for each combination of feedback and condition
feed_data_r <- feed_data %>%
  group_by(feedback, condition) %>%
  summarise(total_count = sum(count))

# Merge total counts with count data
feed_data_r <- feed_data_r %>%
  left_join(feed_data, by = c("feedback", "condition"))

# Calculate the proportion of 'press' and 'no_press' for each combination of feedback and condition
mean_proportion_feed_data_r <- feed_data_r %>%
  mutate(mean_proportion_r = count / total_count)


# Calculate standard errors for each group combination
error_data <- mean_proportion_feed_data_r %>%
  group_by(condition, followup_beha, feedback) %>%
  summarise(
    mean_proportion_r = mean(mean_proportion_r),
    std_err = sqrt(var(mean_proportion_r) / n())  # Calculate standard error correctly
  ) %>%
  ungroup()

# Print error_data to verify
error_data


# Plot with error bars
ggplot(mean_proportion_feed_data_r, aes(x = condition, y = mean_proportion_r, fill = followup_beha)) +
  geom_bar(position = "dodge", stat = "identity") +
  geom_errorbar(data = error_data, aes(ymin = mean_proportion_r - std_err, ymax = mean_proportion_r + std_err),
                position = position_dodge(width = 0.9), width = 0.25) +  # Error bars
  facet_wrap(~ feedback, scales = "free") +  # Facet by feedback
  labs(title = "Mean Proportion of Response after Different Types of Feedback and Condition",
       x = "Condition", y = "Mean Proportion") +
  scale_fill_manual(values = c("press" = "lightgreen", "no_press" = "pink")) +
  theme_minimal() +
  scale_y_continuous(limits = c(0, 0.65), breaks = seq(0, 0.7, 0.1))  # Set y-axis limit and breaks




                                  #accuracy

# A# Filter data for rows where feedback is "win", "lose", or "neutral" and select relevant columns
accuracy_data <- subset(tus_filtered, feedback %in% c("win", "lose", "neutral"), select = c("feedback", "followup_beha", "correct", "condition"))

# Exclude NA values
accuracy_data <- na.omit(accuracy_data)

# Create a grouped bar plot showing the mean of correct responses after each type of feedback for accuracy
# Check the range of the 'correct' variable
summary(accuracy_data$correct)

# Assuming the minimum value is 0.25 or greater, set the y-axis limits using coord_cartesian
ggplot(accuracy_data, aes(x = feedback, fill = followup_beha, y = correct)) +
  geom_bar(position = "dodge", color = "black", stat = "summary", fun = "mean") +
  labs(title = "Mean Correct Responses after Different Types of Feedback (Accuracy)",
       x = "Feedback", y = "Mean Correct Response") +
  scale_fill_manual(values = c("press" = "lightgreen", "no_press" = "pink")) +
  theme_minimal() +
  #facet_grid(~condition)+
  coord_cartesian(ylim = c(0.2, 1))




       #mean condition accuracy
# Filter data for rows where feedback is "win", "lose", or "neutral" and select relevant columns
feedback_data <- subset(tus_filtered, feedback %in% c("win", "lose", "neutral"), select = c("feedback", "followup_beha", "condition", "correct"))

# Exclude NA values
feedback_data <- na.omit(feedback_data)

# Calculate the mean of 'correct' per condition
accuracy_data <- aggregate(correct ~ feedback + followup_beha + condition, data = feedback_data, FUN = mean)

# Create a grouped bar plot showing the mean of correct responses after each type of feedback, separated by condition
ggplot(accuracy_data, aes(x = feedback, y = correct, fill = followup_beha)) +
  geom_bar(position = "dodge", color = "black", stat = "identity") +
  facet_wrap(~ condition, scales = "free") +  # Facet by condition
  labs(title = "Mean Correct Responses after Different Types of Feedback by Condition",
       x = "Feedback", y = "Mean Correct Response") +
  scale_fill_manual(values = c("press" = "lightgreen", "no_press" = "pink")) +
  theme_minimal() +
  coord_cartesian(ylim = c(0.3, 1)) # Set the y-axis limits
```



           #mean RT after different types of feedback
```{r}
#A# Filter data for rows where feedback is "win", "lose", or "neutral" and select relevant columns
rt_data <- subset(tus_filtered, feedback %in% c("win", "lose", "neutral"), select = c("feedback", "followup_beha","condition", "RT", "req_action", "OutValence"))

# Exclude NA values
rt_data <- na.omit(rt_data)

# Create a grouped bar plot showing the mean of reaction times after each type of feedback for RT
ggplot(rt_data, aes(x = feedback, fill = followup_beha, y = RT)) +
  geom_bar(position = "dodge", color = "black", stat = "summary", fun = "mean") +
  labs(title = "Mean Reaction Time after Different Types of Feedback (RT)",
       x = "Feedback", y = "Mean Reaction Time") +
  scale_fill_manual(values = c("press" = "lightgreen", "no_press" = "pink")) +
  theme_minimal()+
  coord_cartesian(ylim = c(0, 600))

# Create a grouped bar plot showing the mean of reaction times after each type of feedback for RT per condition
ggplot(rt_data, aes(x = feedback, fill = feedback, y = RT)) +
  geom_bar(position = "dodge", color = "black", stat = "summary", fun = "mean") +
  labs(title = "Mean Reaction Time after Different Types of Feedback (RT)",
       x = "Feedback", y = "Mean Reaction Time") +
  scale_fill_manual(values = c("lose" = "pink", "win" = "lightgreen", neutral ="lightyellow")) +
  theme_minimal()+
  facet_wrap(~req_action*condition)+
  coord_cartesian(ylim = c(0, 600))


# Create a grouped bar plot showing the mean of reaction times after each type of feedback for RT per condition
ggplot(rt_data, aes(x = feedback, fill = followup_beha, y = RT)) +
  geom_bar(position = "dodge", color = "black", stat = "summary", fun = "mean") +
  labs(title = "Mean Reaction Time after Different Types of Feedback (RT)",
       x = "Feedback", y = "Mean Reaction Time") +
 scale_fill_manual(values = c("press" = "lightgreen", "no_press" = "pink")) +
  theme_minimal()+
  facet_wrap(~condition)+
  coord_cartesian(ylim = c(0, 600))
            
```

   # foolow_up beha per cue interesting
```{r}
# Filter data for rows where feedback is "win", "lose", or "neutral" and select relevant columns
feedback_data <- subset(tus_filtered, feedback %in% c("win", "lose", "neutral"), 
                        select = c("feedback", "followup_beha", "condition", "Cue"))

# Exclude NA values
feedback_data <- na.omit(feedback_data)

# Filter data for "GW" and "GAL" cues
    #feedback_data <- feedback_data %>%
  #filter(Cue %in% c("GW", "GAL"))

# Calculate counts of 'press' and 'no_press' for each combination of feedback, followup_beha, condition, and Cue
count_data <- feedback_data %>%
  group_by(feedback, followup_beha, condition, Cue) %>%
  summarise(count = n()) %>%
  ungroup()

# Calculate the total counts (sum of 'press' and 'no_press') for each combination of feedback, condition, and Cue
total_counts <- count_data %>%
  group_by(feedback, condition, Cue) %>%
  summarise(total_count = sum(count))

# Merge total counts with count data
count_data <- count_data %>%
  left_join(total_counts, by = c("feedback", "condition", "Cue"))

# Calculate the proportion of 'press' and 'no_press' for each combination of feedback, condition, and Cue
mean_proportion <- count_data %>%
  mutate(mean_proportion = count / total_count)

# Create a grouped bar plot showing the mean proportion of responses after each type of feedback, separated by condition and Cue
ggplot(mean_proportion, aes(x = feedback, y = mean_proportion, fill = followup_beha)) +
  geom_bar(position = "dodge", stat = "identity") +
  facet_grid(Cue ~ condition) +  # Facet by condition and Cue
  labs(title = "Mean Proportion of Response after Different Types of Feedback by Condition and Cue",
       x = "Feedback", y = "Mean Proportion") +
  scale_fill_manual(values = c("press" = "lightgreen", "no_press" = "pink")) +
  theme_minimal() +
  scale_y_continuous(limits = c(0, 0.7), breaks = seq(0, 1, 0.1))  # Set y-axis limit and breaks



```








##FOLLOW UP BEHAVIOUR CORRECT FEEDBACK

```{r}

   #Filter data for rows where feedback is "win", "lose", or "neutral" and select relevant columns
feedback_data_r <- subset(tus_filtered, feedback %in% c("win", "lose", "neutral"), select = c("feedback", "followup_correctfeed", "condition"))

# Exclude NA values
feedback_data_r <- na.omit(feedback_data_r)

              #mean per condition for the followup_beha - not stacked [KEEP]

# Calculate counts of 'press' and 'no_press' for each combination of feedback, followup_beha, and condition
count_data_r <- feedback_data_r %>%
  group_by(feedback, followup_correctfeed, condition) %>%
  summarise(count = n()) %>%
  ungroup()

# Calculate the total counts (sum of 'press' and 'no_press') for each combination of feedback and condition
total_counts_r <- count_data_r %>%
  group_by(feedback, condition) %>%
  summarise(total_count = sum(count))

# Merge total counts with count data
count_data_r <- count_data_r %>%
  left_join(total_counts_r, by = c("feedback", "condition"))

# Calculate the proportion of 'press' and 'no_press' for each combination of feedback and condition
mean_proportion_r <- count_data_r %>%
  mutate(mean_proportion_r = count / total_count)

# Create a grouped bar plot showing the mean proportion of responses after each type of feedback, separated by condition
ggplot(mean_proportion_r, aes(x = feedback, y = mean_proportion_r,fill = followup_correctfeed)) +
  geom_bar(data = subset(mean_proportion_r, followup_correctfeed %in% c("press", "no_press")),
           position = "dodge", stat = "identity") +
  facet_wrap(~ condition, scales = "free") +  # Facet by condition
  labs(title = "Mean Proportion of Response after Different Types of Correct Feedback (per Condition)",
       x = "Feedback", y = "Mean Proportion") +
  scale_fill_manual(values = c("press" = "lightgreen", "no_press" = "pink")) +
  theme_minimal() +
  scale_y_continuous(limits = c(0, 0.6), breaks = seq(0, 1, 0.1))  # Set y-axis limit and breaks





             #[per cue]

# Filter data for rows where feedback is "win", "lose", or "neutral" and select relevant columns
feedback_data_rcue <- subset(tus_filtered, feedback %in% c("win", "lose", "neutral"), 
                        select = c("feedback", "followup_correctfeed", "condition", "Cue"))

# Exclude NA values and wrongfeedback
feedback_data_rcue <- na.omit(feedback_data_rcue)


# Filter data for "GW" and "GAL" cues
    #feedback_data_rcue <- feedback_data_rcue %>%
    #filter(Cue %in% c("GW"))

# Calculate counts of 'press' and 'no_press' for each combination of feedback, followup_beha, condition, and Cue
count_data_rcue <- feedback_data_rcue %>%
  group_by(feedback, followup_correctfeed, condition, Cue) %>%
  summarise(count = n()) %>%
  ungroup()

# Calculate the total counts (sum of 'press' and 'no_press') for each combination of feedback, condition, and Cue
total_counts_rcue <- count_data_rcue %>%
  group_by(feedback, condition, Cue) %>%
  summarise(total_count = sum(count))

# Merge total counts with count data
count_data_rcue <- count_data_rcue %>%
  left_join(total_counts, by = c("feedback", "condition", "Cue"))

# Calculate the proportion of 'press' and 'no_press' for each combination of feedback, condition, and Cue
mean_proportion_rcue <- count_data_rcue %>%
  mutate(mean_proportion_rcue = count / total_count)

# Create the grouped bar plot with filtering inside ggplot
ggplot(mean_proportion_rcue, aes(x = feedback, y = mean_proportion_rcue, fill = followup_correctfeed)) +
  geom_bar(data = subset(mean_proportion_rcue, followup_correctfeed %in% c("press", "no_press")),
           position = "dodge", stat = "identity") +
  facet_grid(Cue ~ condition) +  # Facet by condition and Cue
  labs(title = "Mean Proportion of Response after Different Types of Correct Feedback by Condition and Cue",
       x = "Feedback", y = "Mean Proportion") +
  scale_fill_manual(values = c("press" = "lightgreen", "no_press" = "pink")) +
  theme_minimal() +
  scale_y_continuous(limits = c(0, 0.4), breaks = seq(0, 0.4, 0.1))  # Set y-axis limit and breaks

```

RTs reward
```{r}

```




ALSO DO

-	a) follow up behaviour after unsuccessfull stop (pressed while a noGo) and 
-	b) follow up behaviour after positive or after correct feedback (80% of the cases, as the other 20% was a random opposite feedback). !!!--.> 

Cai and colleagues (2014): (1) rAI and salience networks may contribute to inhibitory control by detecting salient stopping events; 
- c) Go Cues behaviour (there is something going on in my data for sure, and (2) rAI and salience networks may directly recruit inhibition by slowing down responses after salient events 
- d) RTs followup after positive or negative feedback maybe, found for WIN only?  GW, NGW, GAL, NGL ? As, GW and NGW more salient that is why AI significant and GW more presses for AI? 
-	E) follow up after positive and negative feedback only	
-	


#REWARD accuracy
```{r}


# Filter data
tus_cl <- tus_filtered %>%
  filter(!is.na(Cue), !is.na(reward), !is.na(followup_beha_reward), !is.na(feedback))

# Calculate proportions and standard errors for each combination of condition, reward, followup_beha_reward, and feedback
proportions <- tus_cl %>%
  group_by(condition, reward, followup_beha_reward, feedback) %>%
  summarise(
    RT = mean(RT, na.rm = TRUE),
    se = sd(RT, na.rm = TRUE) / sqrt(n()),
    .groups = 'drop'
  )

# Plotting the grouped bar plot with error bars for reward
grouped_barplot <- ggplot(proportions, aes(x = reward, y = RT, fill = followup_beha_reward)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_errorbar(aes(ymin = RT - 1.96 * se, ymax = RT + 1.96 * se),
                position = position_dodge(width = 0.9), width = 0.2) +
  facet_wrap(~ condition, scales = "free_y") +
  labs(x = "Reward", y = "RT", fill = "Follow-up Behavior") +
  theme_minimal()

# Display the plot
print(grouped_barplot)

# Plotting the grouped bar plot with error bars for feedback
grouped_barplotf <- ggplot(proportions, aes(x = feedback, y = RT, fill = followup_beha_reward)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_errorbar(aes(ymin = RT - 1.96 * se, ymax = RT + 1.96 * se),
                position = position_dodge(width = 0.9), width = 0.2) +
  facet_wrap(~ condition, scales = "free_y") +
  labs(x = "Feedback", y = "RT", fill = "Follow-up Behavior") +
  theme_minimal()

# Display the plot
print(grouped_barplotf)


```

